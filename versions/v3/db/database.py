#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“è¿æ¥å’Œä¼šè¯ç®¡ç†
æ”¯æŒ SQLite (æœ¬åœ°) å’Œ Supabase (äº‘ç«¯)
"""
import os
import sqlite3
from contextlib import contextmanager
from datetime import datetime, date

# å¯¼å…¥ Supabase å±‚
try:
    from db.supabase_db import (
        is_supabase_available, 
        query_scan_results_supabase,
        get_scanned_dates_supabase,
        get_db_stats_supabase,
        insert_scan_result_supabase
    )
    SUPABASE_LAYER_AVAILABLE = True
except ImportError:
    SUPABASE_LAYER_AVAILABLE = False

# é¿å…é‡å¤åˆ·å±æ—¥å¿—
_SUPABASE_LAG_WARNED = False

# æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ Supabase
USE_SUPABASE = os.environ.get('SUPABASE_URL') is not None

# æ•°æ®åº“æ–‡ä»¶è·¯å¾„ (SQLite å¤‡ç”¨)
DB_DIR = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(DB_DIR, "coral_creek.db")


def get_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row  # è¿”å›å­—å…¸æ ¼å¼
    return conn


@contextmanager
def get_db():
    """æ•°æ®åº“è¿æ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    conn = get_connection()
    try:
        yield conn
        conn.commit()
    except Exception as e:
        conn.rollback()
        raise e
    finally:
        conn.close()


def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
    with get_db() as conn:
        cursor = conn.cursor()
        
        # æ‰«æç»“æœè¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS scan_results (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol VARCHAR(20) NOT NULL,
                scan_date DATE NOT NULL,
                price REAL,
                turnover_m REAL,
                blue_daily REAL,
                blue_weekly REAL,
                blue_monthly REAL,
                adx REAL,
                volatility REAL,
                is_heima BOOLEAN,
                is_juedi BOOLEAN,
                heima_daily BOOLEAN,
                heima_weekly BOOLEAN,
                heima_monthly BOOLEAN,
                juedi_daily BOOLEAN,
                juedi_weekly BOOLEAN,
                juedi_monthly BOOLEAN,
                strat_d_trend BOOLEAN,
                strat_c_resonance BOOLEAN,
                legacy_signal BOOLEAN,
                regime VARCHAR(50),
                adaptive_thresh REAL,
                vp_rating VARCHAR(20),
                profit_ratio REAL,
                wave_phase VARCHAR(50),
                wave_desc VARCHAR(100),
                chan_signal VARCHAR(50),
                chan_desc VARCHAR(100),
                market_cap REAL,
                cap_category VARCHAR(30),
                company_name VARCHAR(200),
                industry VARCHAR(200),
                day_high REAL,
                day_low REAL,
                day_close REAL,
                stop_loss REAL,
                shares_rec INTEGER,
                risk_reward_score REAL,
                market VARCHAR(10) DEFAULT 'US',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(symbol, scan_date)
            )
        """)
        
        # åˆ›å»ºç´¢å¼•
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_scan_date ON scan_results(scan_date)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_symbol ON scan_results(symbol)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_blue_daily ON scan_results(blue_daily)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_scan_date_blue ON scan_results(scan_date, blue_daily)")
        
        # æ·»åŠ æ–°çš„é»‘é©¬å­—æ®µ (å¦‚æœä¸å­˜åœ¨)
        new_heima_cols = [
            ('heima_daily', 'BOOLEAN'),
            ('heima_weekly', 'BOOLEAN'),
            ('heima_monthly', 'BOOLEAN'),
            ('juedi_daily', 'BOOLEAN'),
            ('juedi_weekly', 'BOOLEAN'),
            ('juedi_monthly', 'BOOLEAN'),
        ]
        for col_name, col_type in new_heima_cols:
            try:
                cursor.execute(f"ALTER TABLE scan_results ADD COLUMN {col_name} {col_type}")
            except:
                pass  # åˆ—å·²å­˜åœ¨
        # æ—¥çº¿OHLCè¡¥å……å­—æ®µï¼ˆç”¨äºæ›´ç²¾ç¡®çš„KDJ/èƒŒç¦»è¯„ä¼°ï¼‰
        for col_name, col_type in [("day_high", "REAL"), ("day_low", "REAL"), ("day_close", "REAL")]:
            try:
                cursor.execute(f"ALTER TABLE scan_results ADD COLUMN {col_name} {col_type}")
            except Exception:
                pass
        
        # æ‰«æä»»åŠ¡è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS scan_jobs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                scan_date DATE NOT NULL UNIQUE,
                market VARCHAR(10) DEFAULT 'US',
                status VARCHAR(20) DEFAULT 'pending',
                total_stocks INTEGER DEFAULT 0,
                scanned_stocks INTEGER DEFAULT 0,
                signals_found INTEGER DEFAULT 0,
                started_at TIMESTAMP,
                finished_at TIMESTAMP,
                error_message TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_job_status ON scan_jobs(status)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_job_date ON scan_jobs(scan_date)")
        
        # è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯è¡¨ (ç¼“å­˜æ‰€æœ‰è‚¡ç¥¨çš„åç§°ã€è¡Œä¸šç­‰)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS stock_info (
                symbol VARCHAR(20) PRIMARY KEY,
                name VARCHAR(200),
                industry VARCHAR(200),
                area VARCHAR(100),
                market VARCHAR(10),
                list_date VARCHAR(20),
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_stock_market ON stock_info(market)")
        
        # ä¿¡å·æ€§èƒ½ç¼“å­˜è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS signal_performance (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol VARCHAR(20),
                scan_date VARCHAR(20),
                market VARCHAR(10) DEFAULT 'US',
                return_5d REAL,
                return_10d REAL,
                return_20d REAL,
                max_gain REAL,
                max_drawdown REAL,
                calculated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(symbol, scan_date, market)
            )
        """)
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_perf_date ON signal_performance(scan_date)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_perf_market ON signal_performance(market)")

        # å€™é€‰ä¿¡å·æŒç»­è¿½è¸ªè¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS candidate_tracking (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol VARCHAR(20) NOT NULL,
                market VARCHAR(10) DEFAULT 'US',
                signal_date DATE NOT NULL,
                source VARCHAR(50) DEFAULT 'daily_scan',
                signal_price REAL NOT NULL,
                current_price REAL,
                pnl_pct REAL DEFAULT 0,
                days_since_signal INTEGER DEFAULT 0,
                first_positive_day INTEGER,
                first_nonpositive_after_positive_day INTEGER,
                max_up_pct REAL DEFAULT 0,
                max_drawdown_pct REAL DEFAULT 0,
                pnl_d1 REAL,
                pnl_d3 REAL,
                pnl_d5 REAL,
                pnl_d10 REAL,
                pnl_d20 REAL,
                cap_category VARCHAR(30),
                industry VARCHAR(200),
                signal_tags TEXT,
                blue_daily REAL,
                blue_weekly REAL,
                blue_monthly REAL,
                heima_daily BOOLEAN,
                heima_weekly BOOLEAN,
                heima_monthly BOOLEAN,
                juedi_daily BOOLEAN,
                juedi_weekly BOOLEAN,
                juedi_monthly BOOLEAN,
                vp_rating VARCHAR(20),
                profit_ratio REAL,
                status VARCHAR(20) DEFAULT 'tracking',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(symbol, market, signal_date)
            )
        """)
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_candidate_date ON candidate_tracking(signal_date)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_candidate_market ON candidate_tracking(market)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_candidate_status ON candidate_tracking(status)")
        try:
            cursor.execute("SELECT first_nonpositive_after_positive_day FROM candidate_tracking LIMIT 1")
        except Exception:
            cursor.execute("ALTER TABLE candidate_tracking ADD COLUMN first_nonpositive_after_positive_day INTEGER")
        for col_name in ["juedi_daily", "juedi_weekly", "juedi_monthly"]:
            try:
                cursor.execute(f"ALTER TABLE candidate_tracking ADD COLUMN {col_name} BOOLEAN")
            except Exception:
                pass
        
        # Baseline æ‰«æç»“æœè¡¨ (ç”¨äºå¯¹æ¯”)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS baseline_scan_results (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol VARCHAR(20) NOT NULL,
                scan_date DATE NOT NULL,
                scan_time VARCHAR(10) DEFAULT 'post',  -- pre/mid/post
                market VARCHAR(10) DEFAULT 'US',
                price REAL,
                turnover_m REAL,
                blue_daily REAL,
                blue_weekly REAL,
                blue_days INTEGER,
                blue_weeks INTEGER,
                latest_day_blue REAL,
                latest_week_blue REAL,
                has_day_week_blue BOOLEAN,
                company_name VARCHAR(200),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(symbol, scan_date, market, scan_time)
            )
        """)
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_baseline_date ON baseline_scan_results(scan_date)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_baseline_market ON baseline_scan_results(market)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_baseline_symbol ON baseline_scan_results(symbol)")
        
        # äº¤æ˜“è®°å½•è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS trades (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol VARCHAR(20) NOT NULL,
                market VARCHAR(10) DEFAULT 'US',
                trade_type VARCHAR(10) NOT NULL,
                price REAL NOT NULL,
                shares INTEGER NOT NULL,
                trade_date DATE NOT NULL,
                notes TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_trades_symbol ON trades(symbol)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_trades_date ON trades(trade_date)")
        
        # æŒä»“/å…³æ³¨åˆ—è¡¨è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS watchlist (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol VARCHAR(20) NOT NULL,
                market VARCHAR(10) DEFAULT 'US',
                entry_date DATE NOT NULL,
                entry_price REAL NOT NULL,
                shares INTEGER DEFAULT 0,
                status VARCHAR(20) DEFAULT 'holding',
                notes TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(symbol, market, entry_date)
            )
        """)
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_watchlist_symbol ON watchlist(symbol)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_watchlist_status ON watchlist(status)")

        # åº”ç”¨è®¾ç½®è¡¨ï¼ˆç”¨äºæŒä¹…åŒ– UI åå¥½ï¼‰
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS app_settings (
                setting_key VARCHAR(100) PRIMARY KEY,
                setting_value TEXT,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # è¿ç§»: å¦‚æœ market åˆ—ä¸å­˜åœ¨ï¼Œæ·»åŠ å®ƒ
        try:
            cursor.execute("SELECT market FROM scan_results LIMIT 1")
        except sqlite3.OperationalError:
            print("ğŸ”„ Adding market column to scan_results...")
            cursor.execute("ALTER TABLE scan_results ADD COLUMN market VARCHAR(10) DEFAULT 'US'")
        
        print(f"âœ… Database initialized at: {DB_PATH}")


def get_app_setting(setting_key, default=None):
    """è¯»å–åº”ç”¨è®¾ç½®å€¼ï¼ˆå­—ç¬¦ä¸²ï¼‰"""
    def _query_setting():
        with get_db() as conn:
            cursor = conn.cursor()
            cursor.execute(
                "SELECT setting_value FROM app_settings WHERE setting_key = ?",
                (setting_key,),
            )
            row = cursor.fetchone()
            return row["setting_value"] if row else default

    try:
        return _query_setting()
    except sqlite3.OperationalError as e:
        if "no such table" in str(e).lower():
            init_db()
            return _query_setting()
        raise


def set_app_setting(setting_key, setting_value):
    """å†™å…¥åº”ç”¨è®¾ç½®å€¼ï¼ˆå­—ç¬¦ä¸²ï¼‰"""
    def _upsert_setting():
        with get_db() as conn:
            cursor = conn.cursor()
            cursor.execute(
                """
                INSERT INTO app_settings (setting_key, setting_value, updated_at)
                VALUES (?, ?, CURRENT_TIMESTAMP)
                ON CONFLICT(setting_key) DO UPDATE SET
                    setting_value = excluded.setting_value,
                    updated_at = CURRENT_TIMESTAMP
                """,
                (setting_key, setting_value),
            )

    try:
        _upsert_setting()
    except sqlite3.OperationalError as e:
        if "no such table" in str(e).lower():
            init_db()
            _upsert_setting()
        else:
            raise


def get_scanned_dates(start_date=None, end_date=None, market=None):
    """è·å–å·²æ‰«æçš„æ—¥æœŸåˆ—è¡¨ - ä¼˜å…ˆä½¿ç”¨ Supabase"""
    def _sqlite_dates():
        def _query_dates():
            with get_db() as conn:
                cursor = conn.cursor()

                query = "SELECT DISTINCT scan_date FROM scan_results WHERE 1=1"
                params = []

                if start_date:
                    query += " AND scan_date >= ?"
                    params.append(start_date)
                if end_date:
                    query += " AND scan_date <= ?"
                    params.append(end_date)
                if market:
                    query += " AND market = ?"
                    params.append(market)

                query += " ORDER BY scan_date DESC"
                cursor.execute(query, params)
                return [row['scan_date'] for row in cursor.fetchall()]

        try:
            return _query_dates()
        except sqlite3.OperationalError as e:
            if "no such table" in str(e).lower():
                # é¦–æ¬¡è¿è¡Œæˆ–ç©º DBï¼šå…ˆåˆå§‹åŒ–è¡¨ç»“æ„ï¼Œå†è¿”å›ç©ºåˆ—è¡¨
                try:
                    init_db()
                    return _query_dates()
                except Exception as e2:
                    print(f"âš ï¸ SQLite åˆå§‹åŒ–åä»æ— æ³•è¯»å–æ‰«ææ—¥æœŸ: {e2}")
                    return []
            raise

    # ä¼˜å…ˆä½¿ç”¨ Supabase
    if USE_SUPABASE and SUPABASE_LAYER_AVAILABLE:
        try:
            dates = get_scanned_dates_supabase(start_date, end_date, market)
            # å®¹é”™: è‹¥ Supabase æ—¥æœŸè½åäºæœ¬åœ° SQLiteï¼Œåˆ™ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æœ€æ–°æ—¥æœŸ
            local_dates = _sqlite_dates()
            if dates and local_dates:
                if str(dates[0]) >= str(local_dates[0]):
                    return dates
                global _SUPABASE_LAG_WARNED
                if not _SUPABASE_LAG_WARNED:
                    print(f"âš ï¸ Supabase æ—¥æœŸè½å (supabase={dates[0]}, sqlite={local_dates[0]}), å›é€€ SQLite")
                    _SUPABASE_LAG_WARNED = True
                return local_dates
            if dates:
                return dates
            if local_dates:
                return local_dates
        except Exception as e:
            print(f"âš ï¸ Supabase æ—¥æœŸæŸ¥è¯¢å¤±è´¥: {e}")

    # SQLite å¤‡ç”¨
    return _sqlite_dates()


def get_missing_dates(start_date, end_date):
    """è·å–ç¼ºå¤±çš„äº¤æ˜“æ—¥æœŸ (æ’é™¤å‘¨æœ«)"""
    from datetime import timedelta
    
    scanned = set(get_scanned_dates(start_date, end_date))
    
    missing = []
    current = datetime.strptime(start_date, '%Y-%m-%d').date() if isinstance(start_date, str) else start_date
    end = datetime.strptime(end_date, '%Y-%m-%d').date() if isinstance(end_date, str) else end_date
    
    while current <= end:
        # è·³è¿‡å‘¨æœ« (5=Saturday, 6=Sunday)
        if current.weekday() < 5:
            date_str = current.strftime('%Y-%m-%d')
            if date_str not in scanned:
                missing.append(date_str)
        current += timedelta(days=1)
    
    return missing


def insert_scan_result(result_dict):
    """æ’å…¥æˆ–æ›´æ–°å•æ¡æ‰«æç»“æœ - åŒæ—¶å†™å…¥ SQLite å’Œ Supabase"""
    # 1. å†™å…¥ SQLite (æœ¬åœ°å¤‡ä»½)
    with get_db() as conn:
        cursor = conn.cursor()
        
        # UPSERT: å¦‚æœå­˜åœ¨åˆ™æ›´æ–°ï¼Œä¸å­˜åœ¨åˆ™æ’å…¥
        cursor.execute("""
            INSERT INTO scan_results (
                symbol, scan_date, price, turnover_m, blue_daily, blue_weekly, blue_monthly,
                adx, volatility, is_heima, is_juedi, 
                heima_daily, heima_weekly, heima_monthly, juedi_daily, juedi_weekly, juedi_monthly,
                strat_d_trend, strat_c_resonance,
                legacy_signal, regime, adaptive_thresh, vp_rating, profit_ratio,
                wave_phase, wave_desc, chan_signal, chan_desc, market_cap, cap_category,
                company_name, industry, day_high, day_low, day_close, stop_loss, shares_rec, risk_reward_score, market, updated_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
            ON CONFLICT(symbol, scan_date) DO UPDATE SET
                price = excluded.price,
                turnover_m = excluded.turnover_m,
                blue_daily = excluded.blue_daily,
                blue_weekly = excluded.blue_weekly,
                blue_monthly = excluded.blue_monthly,
                adx = excluded.adx,
                volatility = excluded.volatility,
                is_heima = excluded.is_heima,
                is_juedi = excluded.is_juedi,
                heima_daily = excluded.heima_daily,
                heima_weekly = excluded.heima_weekly,
                heima_monthly = excluded.heima_monthly,
                juedi_daily = excluded.juedi_daily,
                juedi_weekly = excluded.juedi_weekly,
                juedi_monthly = excluded.juedi_monthly,
                strat_d_trend = excluded.strat_d_trend,
                strat_c_resonance = excluded.strat_c_resonance,
                legacy_signal = excluded.legacy_signal,
                regime = excluded.regime,
                adaptive_thresh = excluded.adaptive_thresh,
                vp_rating = excluded.vp_rating,
                profit_ratio = excluded.profit_ratio,
                wave_phase = excluded.wave_phase,
                wave_desc = excluded.wave_desc,
                chan_signal = excluded.chan_signal,
                chan_desc = excluded.chan_desc,
                market_cap = excluded.market_cap,
                cap_category = excluded.cap_category,
                company_name = excluded.company_name,
                industry = excluded.industry,
                day_high = excluded.day_high,
                day_low = excluded.day_low,
                day_close = excluded.day_close,
                stop_loss = excluded.stop_loss,
                shares_rec = excluded.shares_rec,
                risk_reward_score = excluded.risk_reward_score,
                market = excluded.market,
                updated_at = CURRENT_TIMESTAMP
        """, (
            result_dict.get('Symbol'),
            result_dict.get('Date'),
            result_dict.get('Price'),
            result_dict.get('Turnover_M'),
            result_dict.get('Blue_Daily'),
            result_dict.get('Blue_Weekly'),
            result_dict.get('Blue_Monthly'),
            result_dict.get('ADX'),
            result_dict.get('Volatility'),
            result_dict.get('Is_Heima'),
            result_dict.get('Is_Juedi') if 'Is_Juedi' in result_dict else result_dict.get('Is_Heima'),
            result_dict.get('Heima_Daily'),
            result_dict.get('Heima_Weekly'),
            result_dict.get('Heima_Monthly'),
            result_dict.get('Juedi_Daily'),
            result_dict.get('Juedi_Weekly'),
            result_dict.get('Juedi_Monthly'),
            result_dict.get('Strat_D_Trend'),
            result_dict.get('Strat_C_Resonance'),
            result_dict.get('Legacy_Signal'),
            result_dict.get('Regime'),
            result_dict.get('Adaptive_Thresh'),
            result_dict.get('VP_Rating'),
            result_dict.get('Profit_Ratio'),
            result_dict.get('Wave_Phase'),
            result_dict.get('Wave_Desc'),
            result_dict.get('Chan_Signal'),
            result_dict.get('Chan_Desc'),
            result_dict.get('Market_Cap'),
            result_dict.get('Cap_Category'),
            result_dict.get('Company_Name'),
            result_dict.get('Industry'),
            result_dict.get('Day_High'),
            result_dict.get('Day_Low'),
            result_dict.get('Day_Close') if result_dict.get('Day_Close') is not None else result_dict.get('Price'),
            result_dict.get('Stop_Loss'),
            result_dict.get('Shares_Rec'),
            result_dict.get('Risk_Reward_Score'),
            result_dict.get('Market', 'US')  # é»˜è®¤ US
        ))
    
    # 2. åŒæ­¥å†™å…¥ Supabase (äº‘ç«¯)
    if USE_SUPABASE and SUPABASE_LAYER_AVAILABLE:
        try:
            insert_scan_result_supabase(result_dict)
        except Exception as e:
            pass  # Supabase å¤±è´¥ä¸å½±å“ä¸»æµç¨‹


def bulk_insert_scan_results(results_list):
    """æ‰¹é‡æ’å…¥æ‰«æç»“æœ"""
    for result in results_list:
        insert_scan_result(result)


def query_scan_results(scan_date=None, start_date=None, end_date=None, 
                       min_blue=None, symbols=None, market=None, limit=None):
    """æŸ¥è¯¢æ‰«æç»“æœ - ä¼˜å…ˆä½¿ç”¨ Supabase"""
    # ä¼˜å…ˆä½¿ç”¨ Supabase
    if USE_SUPABASE and SUPABASE_LAYER_AVAILABLE:
        try:
            results = query_scan_results_supabase(
                scan_date=scan_date,
                start_date=start_date,
                end_date=end_date,
                min_blue=min_blue,
                market=market,
                limit=limit
            )
            if results:
                return results
        except Exception as e:
            print(f"âš ï¸ Supabase æŸ¥è¯¢å¤±è´¥ï¼Œå›é€€åˆ° SQLite: {e}")
    
    # SQLite å¤‡ç”¨
    def _sqlite_query():
        with get_db() as conn:
            cursor = conn.cursor()

            query = "SELECT * FROM scan_results WHERE 1=1"
            params = []

            if scan_date:
                query += " AND scan_date = ?"
                params.append(scan_date)

            if start_date:
                query += " AND scan_date >= ?"
                params.append(start_date)

            if end_date:
                query += " AND scan_date <= ?"
                params.append(end_date)

            if min_blue is not None:
                query += " AND blue_daily >= ?"
                params.append(min_blue)

            if symbols:
                placeholders = ','.join(['?' for _ in symbols])
                query += f" AND symbol IN ({placeholders})"
                params.extend(symbols)

            if market:
                query += " AND market = ?"
                params.append(market)

            query += " ORDER BY scan_date DESC, blue_daily DESC"

            if limit:
                query += f" LIMIT {limit}"

            cursor.execute(query, params)
            return [dict(row) for row in cursor.fetchall()]

    try:
        return _sqlite_query()
    except sqlite3.OperationalError as e:
        if "no such table" in str(e).lower():
            try:
                init_db()
                return _sqlite_query()
            except Exception as e2:
                print(f"âš ï¸ SQLite åˆå§‹åŒ–åä»æ— æ³•æŸ¥è¯¢ scan_results: {e2}")
                return []
        raise


def get_stock_history(symbol, limit=30):
    """è·å–å•åªè‚¡ç¥¨çš„å†å²æ‰«æè®°å½•"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT * FROM scan_results 
            WHERE symbol = ? 
            ORDER BY scan_date DESC 
            LIMIT ?
        """, (symbol, limit))
        return [dict(row) for row in cursor.fetchall()]


def get_first_scan_dates(symbols, market='US'):
    """æ‰¹é‡è·å–è‚¡ç¥¨é¦–æ¬¡å‡ºç°åœ¨æ‰«æç»“æœä¸­çš„æ—¥æœŸ
    
    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        market: å¸‚åœº (US/CN)
    
    Returns:
        dict: {symbol: first_scan_date} 
    """
    if not symbols:
        return {}
    
    # ä¼˜å…ˆä½¿ç”¨ Supabase
    if USE_SUPABASE and SUPABASE_LAYER_AVAILABLE:
        try:
            from db.supabase_db import get_first_scan_dates_supabase
            result = get_first_scan_dates_supabase(symbols, market)
            if result:
                return result
        except Exception as e:
            print(f"âš ï¸ Supabase è·å–é¦–æ¬¡æ—¥æœŸå¤±è´¥ï¼Œå›é€€ SQLite: {e}")
    
    # SQLite å¤‡ç”¨
    with get_db() as conn:
        cursor = conn.cursor()
        placeholders = ','.join(['?' for _ in symbols])
        cursor.execute(f"""
            SELECT symbol, MIN(scan_date) as first_date
            FROM scan_results 
            WHERE symbol IN ({placeholders}) AND market = ?
            GROUP BY symbol
        """, symbols + [market])
        
        result = {}
        for row in cursor.fetchall():
            result[row['symbol']] = row['first_date']
        return result


def get_scan_job(scan_date):
    """è·å–æ‰«æä»»åŠ¡çŠ¶æ€"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM scan_jobs WHERE scan_date = ?", (scan_date,))
        row = cursor.fetchone()
        return dict(row) if row else None


def create_scan_job(scan_date, market='US'):
    """åˆ›å»ºæ‰«æä»»åŠ¡"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            INSERT OR REPLACE INTO scan_jobs (scan_date, market, status, created_at)
            VALUES (?, ?, 'pending', CURRENT_TIMESTAMP)
        """, (scan_date, market))


def update_scan_job(scan_date, **kwargs):
    """æ›´æ–°æ‰«æä»»åŠ¡çŠ¶æ€"""
    with get_db() as conn:
        cursor = conn.cursor()
        
        set_clauses = []
        params = []
        
        for key, value in kwargs.items():
            set_clauses.append(f"{key} = ?")
            params.append(value)
        
        params.append(scan_date)
        
        cursor.execute(f"""
            UPDATE scan_jobs SET {', '.join(set_clauses)}
            WHERE scan_date = ?
        """, params)


def get_db_stats():
    """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯ - ä¼˜å…ˆä½¿ç”¨ Supabase"""
    # ä¼˜å…ˆä½¿ç”¨ Supabase
    if USE_SUPABASE and SUPABASE_LAYER_AVAILABLE:
        try:
            stats = get_db_stats_supabase()
            if stats and stats.get('total_records', 0) > 0:
                return stats
        except Exception as e:
            print(f"âš ï¸ Supabase stats å¤±è´¥: {e}")
    
    # SQLite å¤‡ç”¨
    with get_db() as conn:
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) as total FROM scan_results")
        total_records = cursor.fetchone()['total']
        
        cursor.execute("SELECT COUNT(DISTINCT symbol) as total FROM scan_results")
        total_symbols = cursor.fetchone()['total']
        
        cursor.execute("SELECT COUNT(DISTINCT scan_date) as total FROM scan_results")
        total_dates = cursor.fetchone()['total']
        
        cursor.execute("SELECT MIN(scan_date) as min_date, MAX(scan_date) as max_date FROM scan_results")
        date_range = cursor.fetchone()
        
        return {
            'total_records': total_records,
            'total_symbols': total_symbols,
            'total_dates': total_dates,
            'min_date': date_range['min_date'],
            'max_date': date_range['max_date']
        }


# ========== è‚¡ç¥¨ä¿¡æ¯ç¼“å­˜ ==========

def upsert_stock_info(symbol, name, industry=None, area=None, market='US', list_date=None):
    """æ’å…¥æˆ–æ›´æ–°è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            INSERT INTO stock_info (symbol, name, industry, area, market, list_date, updated_at)
            VALUES (?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
            ON CONFLICT(symbol) DO UPDATE SET
                name = excluded.name,
                industry = excluded.industry,
                area = excluded.area,
                market = excluded.market,
                list_date = excluded.list_date,
                updated_at = CURRENT_TIMESTAMP
        """, (symbol, name, industry, area, market, list_date))


def bulk_upsert_stock_info(stock_list):
    """æ‰¹é‡æ’å…¥è‚¡ç¥¨ä¿¡æ¯ - stock_list: [{'symbol': '', 'name': '', 'industry': '', 'market': ''}, ...]"""
    with get_db() as conn:
        cursor = conn.cursor()
        for stock in stock_list:
            cursor.execute("""
                INSERT INTO stock_info (symbol, name, industry, area, market, list_date, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
                ON CONFLICT(symbol) DO UPDATE SET
                    name = excluded.name,
                    industry = excluded.industry,
                    area = excluded.area,
                    market = excluded.market,
                    list_date = excluded.list_date,
                    updated_at = CURRENT_TIMESTAMP
            """, (
                stock.get('symbol'),
                stock.get('name'),
                stock.get('industry'),
                stock.get('area'),
                stock.get('market', 'US'),
                stock.get('list_date')
            ))


def get_stock_info(symbol):
    """è·å–å•åªè‚¡ç¥¨çš„åŸºæœ¬ä¿¡æ¯"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM stock_info WHERE symbol = ?", (symbol,))
        row = cursor.fetchone()
        return dict(row) if row else None


def get_stock_info_batch(symbols):
    """æ‰¹é‡è·å–è‚¡ç¥¨ä¿¡æ¯"""
    if not symbols:
        return {}
    with get_db() as conn:
        cursor = conn.cursor()
        placeholders = ','.join(['?' for _ in symbols])
        cursor.execute(f"SELECT * FROM stock_info WHERE symbol IN ({placeholders})", symbols)
        return {row['symbol']: dict(row) for row in cursor.fetchall()}


def get_stock_info_count(market=None):
    """è·å–è‚¡ç¥¨ä¿¡æ¯æ•°é‡"""
    with get_db() as conn:
        cursor = conn.cursor()
        if market:
            cursor.execute("SELECT COUNT(*) as cnt FROM stock_info WHERE market = ?", (market,))
        else:
            cursor.execute("SELECT COUNT(*) as cnt FROM stock_info")
        return cursor.fetchone()['cnt']


# ==================== Baseline æ‰«æç»“æœæ“ä½œ ====================

def save_baseline_results(results, scan_date, market='US', scan_time='post'):
    """æ‰¹é‡ä¿å­˜ baseline æ‰«æç»“æœ"""
    if not results:
        return 0
    
    with get_db() as conn:
        cursor = conn.cursor()
        saved = 0
        
        for r in results:
            try:
                cursor.execute("""
                    INSERT OR REPLACE INTO baseline_scan_results (
                        symbol, scan_date, scan_time, market, price, turnover_m,
                        blue_daily, blue_weekly, blue_days, blue_weeks,
                        latest_day_blue, latest_week_blue, has_day_week_blue, company_name
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    r.get('symbol'),
                    scan_date,
                    scan_time,
                    market,
                    r.get('price'),
                    r.get('turnover'),
                    r.get('blue_daily'),
                    r.get('blue_weekly'),
                    r.get('blue_days'),
                    r.get('blue_weeks'),
                    r.get('latest_day_blue'),
                    r.get('latest_week_blue'),
                    r.get('has_day_week_blue', True),
                    r.get('name', '')
                ))
                saved += 1
            except Exception as e:
                print(f"Error saving {r.get('symbol')}: {e}")
        
        return saved


def query_baseline_results(scan_date=None, market=None, limit=100):
    """æŸ¥è¯¢ baseline æ‰«æç»“æœ"""
    with get_db() as conn:
        cursor = conn.cursor()
        
        query = "SELECT * FROM baseline_scan_results WHERE 1=1"
        params = []
        
        if scan_date:
            query += " AND scan_date = ?"
            params.append(scan_date)
        if market:
            query += " AND market = ?"
            params.append(market)
        
        query += " ORDER BY latest_day_blue DESC LIMIT ?"
        params.append(limit)
        
        cursor.execute(query, params)
        return [dict(row) for row in cursor.fetchall()]


def compare_scan_results(scan_date, market='US'):
    """æ¯”è¾ƒåŒä¸€å¤©çš„ baseline å’Œå¸¸è§„æ‰«æç»“æœ"""
    with get_db() as conn:
        cursor = conn.cursor()
        
        # è·å– baseline ç»“æœçš„ symbols
        cursor.execute("""
            SELECT symbol FROM baseline_scan_results 
            WHERE scan_date = ? AND market = ?
        """, (scan_date, market))
        baseline_symbols = set(row['symbol'] for row in cursor.fetchall())
        
        # è·å–å¸¸è§„æ‰«æç»“æœçš„ symbols
        cursor.execute("""
            SELECT symbol FROM scan_results 
            WHERE scan_date = ? AND market = ?
        """, (scan_date, market))
        regular_symbols = set(row['symbol'] for row in cursor.fetchall())
        
        return {
            'baseline_only': list(baseline_symbols - regular_symbols),
            'regular_only': list(regular_symbols - baseline_symbols),
            'both': list(baseline_symbols & regular_symbols),
            'baseline_count': len(baseline_symbols),
            'regular_count': len(regular_symbols),
        }


# ==================== Signal Performance Cache ====================

def upsert_signal_performance(symbol: str, scan_date: str, market: str = 'US',
                              return_5d: float = None, return_10d: float = None, 
                              return_20d: float = None, max_gain: float = None,
                              max_drawdown: float = None):
    """æ’å…¥æˆ–æ›´æ–°ä¿¡å·æ€§èƒ½ç¼“å­˜"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            INSERT INTO signal_performance 
            (symbol, scan_date, market, return_5d, return_10d, return_20d, max_gain, max_drawdown, calculated_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
            ON CONFLICT(symbol, scan_date, market) DO UPDATE SET
                return_5d = excluded.return_5d,
                return_10d = excluded.return_10d,
                return_20d = excluded.return_20d,
                max_gain = excluded.max_gain,
                max_drawdown = excluded.max_drawdown,
                calculated_at = CURRENT_TIMESTAMP
        """, (symbol, scan_date, market, return_5d, return_10d, return_20d, max_gain, max_drawdown))


def bulk_upsert_signal_performance(performance_list: list):
    """æ‰¹é‡æ’å…¥ä¿¡å·æ€§èƒ½æ•°æ®"""
    for p in performance_list:
        upsert_signal_performance(
            symbol=p.get('symbol'),
            scan_date=p.get('scan_date'),
            market=p.get('market', 'US'),
            return_5d=p.get('return_5d'),
            return_10d=p.get('return_10d'),
            return_20d=p.get('return_20d'),
            max_gain=p.get('max_gain'),
            max_drawdown=p.get('max_drawdown')
        )


def query_signal_performance(start_date: str = None, end_date: str = None, 
                             market: str = None, limit: int = 1000):
    """æŸ¥è¯¢ä¿¡å·æ€§èƒ½ç¼“å­˜"""
    with get_db() as conn:
        cursor = conn.cursor()
        
        query = """
            SELECT sp.*, sr.blue_daily, sr.price, sr.turnover_m 
            FROM signal_performance sp
            LEFT JOIN scan_results sr ON sp.symbol = sr.symbol AND sp.scan_date = sr.scan_date
            WHERE 1=1
        """
        params = []
        
        if start_date:
            query += " AND sp.scan_date >= ?"
            params.append(start_date)
        if end_date:
            query += " AND sp.scan_date <= ?"
            params.append(end_date)
        if market:
            query += " AND sp.market = ?"
            params.append(market)
        
        query += " ORDER BY sp.scan_date DESC LIMIT ?"
        params.append(limit)
        
        cursor.execute(query, params)
        return [dict(row) for row in cursor.fetchall()]


def get_signals_without_performance(market: str = 'US', min_days_old: int = 5, limit: int = 500):
    """è·å–æ²¡æœ‰æ€§èƒ½ç¼“å­˜çš„ä¿¡å·ï¼ˆç”¨äºè®¡ç®—å‰å‘æ”¶ç›Šï¼‰"""
    with get_db() as conn:
        cursor = conn.cursor()
        
        # åªé€‰æ‹©è‡³å°‘ min_days_old å¤©å‰çš„ä¿¡å·ï¼ˆç¡®ä¿æœ‰è¶³å¤Ÿçš„å‰å‘æ•°æ®ï¼‰
        cursor.execute("""
            SELECT sr.symbol, sr.scan_date, sr.price, sr.blue_daily, sr.market
            FROM scan_results sr
            LEFT JOIN signal_performance sp 
                ON sr.symbol = sp.symbol AND sr.scan_date = sp.scan_date AND sr.market = sp.market
            WHERE sp.id IS NULL
            AND sr.market = ?
            AND DATE(sr.scan_date) <= DATE('now', ? || ' days')
            ORDER BY sr.scan_date DESC
            LIMIT ?
        """, (market, f'-{min_days_old}', limit))
        
        return [dict(row) for row in cursor.fetchall()]


def get_performance_stats(market: str = None):
    """è·å–æ€§èƒ½ç¼“å­˜ç»Ÿè®¡"""
    with get_db() as conn:
        cursor = conn.cursor()
        
        if market:
            cursor.execute("""
                SELECT COUNT(*) as total,
                       AVG(return_5d) as avg_5d,
                       AVG(return_10d) as avg_10d,
                       AVG(return_20d) as avg_20d
                FROM signal_performance WHERE market = ?
            """, (market,))
        else:
            cursor.execute("""
                SELECT COUNT(*) as total,
                       AVG(return_5d) as avg_5d,
                       AVG(return_10d) as avg_10d,
                       AVG(return_20d) as avg_20d
                FROM signal_performance
            """)
        
        row = cursor.fetchone()
        return dict(row) if row else {}


# ==================== äº¤æ˜“å’ŒæŒä»“æ“ä½œ ====================

def get_signal_history(symbol, market='US', limit=50):
    """è·å–è‚¡ç¥¨çš„å†å²ä¿¡å·è®°å½•"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT scan_date, price, turnover_m, blue_daily, blue_weekly, blue_monthly,
                   is_heima, is_juedi, wave_phase, chan_signal
            FROM scan_results 
            WHERE symbol = ? AND market = ?
            ORDER BY scan_date DESC
            LIMIT ?
        """, (symbol, market, limit))
        return [dict(row) for row in cursor.fetchall()]


def add_trade(symbol, trade_type, price, shares, trade_date, market='US', notes=''):
    """æ·»åŠ äº¤æ˜“è®°å½•"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            INSERT INTO trades (symbol, market, trade_type, price, shares, trade_date, notes)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (symbol, market, trade_type.upper(), price, shares, trade_date, notes))
        return cursor.lastrowid


def add_to_watchlist(symbol, entry_price, shares=0, entry_date=None, market='US', status='holding', notes=''):
    """æ·»åŠ è‚¡ç¥¨åˆ°æŒä»“/å…³æ³¨åˆ—è¡¨"""
    if entry_date is None:
        entry_date = datetime.now().strftime('%Y-%m-%d')
    
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            INSERT OR REPLACE INTO watchlist (symbol, market, entry_date, entry_price, shares, status, notes)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (symbol, market, entry_date, entry_price, shares, status, notes))
        return cursor.lastrowid


def get_portfolio(status='holding', market=None):
    """è·å–æŒä»“åˆ—è¡¨"""
    with get_db() as conn:
        cursor = conn.cursor()
        
        query = "SELECT * FROM watchlist WHERE status = ?"
        params = [status]
        
        if market:
            query += " AND market = ?"
            params.append(market)
        
        query += " ORDER BY entry_date DESC"
        cursor.execute(query, params)
        return [dict(row) for row in cursor.fetchall()]


def get_trades(symbol=None, market=None, limit=100):
    """è·å–äº¤æ˜“è®°å½•"""
    with get_db() as conn:
        cursor = conn.cursor()
        
        query = "SELECT * FROM trades WHERE 1=1"
        params = []
        
        if symbol:
            query += " AND symbol = ?"
            params.append(symbol)
        if market:
            query += " AND market = ?"
            params.append(market)
        
        query += " ORDER BY trade_date DESC, created_at DESC LIMIT ?"
        params.append(limit)
        
        cursor.execute(query, params)
        return [dict(row) for row in cursor.fetchall()]


def update_watchlist_status(symbol, entry_date, new_status, market='US'):
    """æ›´æ–°æŒä»“çŠ¶æ€ (holding -> sold)"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            UPDATE watchlist SET status = ? 
            WHERE symbol = ? AND entry_date = ? AND market = ?
        """, (new_status, symbol, entry_date, market))
        return cursor.rowcount


def delete_from_watchlist(symbol, entry_date, market='US'):
    """ä»æŒä»“åˆ—è¡¨åˆ é™¤"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            DELETE FROM watchlist WHERE symbol = ? AND entry_date = ? AND market = ?
        """, (symbol, entry_date, market))
        return cursor.rowcount


# ==================== åšä¸»æ¨èè¿½è¸ª ====================

def init_blogger_tables():
    """åˆå§‹åŒ–åšä¸»æ¨èç›¸å…³è¡¨"""
    with get_db() as conn:
        cursor = conn.cursor()
        
        # åšä¸»è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS bloggers (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL UNIQUE,
                platform TEXT,
                specialty TEXT,
                url TEXT,
                avatar_url TEXT,
                notes TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # æ¨èè®°å½•è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS recommendations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                blogger_id INTEGER NOT NULL,
                ticker TEXT NOT NULL,
                market TEXT DEFAULT 'CN',
                rec_date DATE NOT NULL,
                rec_price REAL,
                rec_type TEXT DEFAULT 'BUY',
                target_price REAL,
                stop_loss REAL,
                portfolio_tag TEXT,
                notes TEXT,
                source_url TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (blogger_id) REFERENCES bloggers(id)
            )
        """)

        # å…¼å®¹æ—§åº“ï¼šè¡¥ portfolio_tag å­—æ®µ
        try:
            cursor.execute("SELECT portfolio_tag FROM recommendations LIMIT 1")
        except Exception:
            cursor.execute("ALTER TABLE recommendations ADD COLUMN portfolio_tag TEXT")
        
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_rec_blogger ON recommendations(blogger_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_rec_date ON recommendations(rec_date)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_rec_ticker ON recommendations(ticker)")
        
        print("âœ… Blogger tables initialized")


def add_blogger(name, platform=None, specialty=None, url=None, notes=None):
    """æ·»åŠ åšä¸»"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            INSERT INTO bloggers (name, platform, specialty, url, notes)
            VALUES (?, ?, ?, ?, ?)
        """, (name, platform, specialty, url, notes))
        return cursor.lastrowid


def get_all_bloggers():
    """è·å–æ‰€æœ‰åšä¸»"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM bloggers ORDER BY name")
        return [dict(row) for row in cursor.fetchall()]


def get_blogger(blogger_id):
    """è·å–å•ä¸ªåšä¸»"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM bloggers WHERE id = ?", (blogger_id,))
        row = cursor.fetchone()
        return dict(row) if row else None


def update_blogger(blogger_id, **kwargs):
    """æ›´æ–°åšä¸»ä¿¡æ¯"""
    with get_db() as conn:
        cursor = conn.cursor()
        set_clauses = [f"{k} = ?" for k in kwargs.keys()]
        params = list(kwargs.values()) + [blogger_id]
        cursor.execute(f"""
            UPDATE bloggers SET {', '.join(set_clauses)} WHERE id = ?
        """, params)
        return cursor.rowcount


def delete_blogger(blogger_id):
    """åˆ é™¤åšä¸»"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("DELETE FROM recommendations WHERE blogger_id = ?", (blogger_id,))
        cursor.execute("DELETE FROM bloggers WHERE id = ?", (blogger_id,))
        return cursor.rowcount


def add_recommendation(blogger_id, ticker, rec_date, market='CN', rec_price=None,
                       rec_type='BUY', target_price=None, stop_loss=None,
                       portfolio_tag=None, notes=None, source_url=None):
    """æ·»åŠ æ¨èè®°å½•"""
    def _insert_once():
        with get_db() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                INSERT INTO recommendations (blogger_id, ticker, market, rec_date, rec_price, 
                                             rec_type, target_price, stop_loss, portfolio_tag, notes, source_url)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (blogger_id, ticker.upper(), market, rec_date, rec_price,
                  rec_type, target_price, stop_loss, portfolio_tag, notes, source_url))
            return cursor.lastrowid

    try:
        return _insert_once()
    except sqlite3.OperationalError as e:
        if "no such column" in str(e).lower() or "no such table" in str(e).lower():
            init_blogger_tables()
            return _insert_once()
        raise


def get_recommendations(blogger_id=None, ticker=None, market=None, start_date=None, end_date=None, portfolio_tag=None, limit=100):
    """æŸ¥è¯¢æ¨èè®°å½•"""
    with get_db() as conn:
        cursor = conn.cursor()
        
        query = """
            SELECT r.*, b.name as blogger_name, b.platform
            FROM recommendations r
            JOIN bloggers b ON r.blogger_id = b.id
            WHERE 1=1
        """
        params = []
        
        if blogger_id:
            query += " AND r.blogger_id = ?"
            params.append(blogger_id)
        if ticker:
            query += " AND r.ticker = ?"
            params.append(ticker.upper())
        if market:
            query += " AND r.market = ?"
            params.append(market)
        if start_date:
            query += " AND r.rec_date >= ?"
            params.append(start_date)
        if end_date:
            query += " AND r.rec_date <= ?"
            params.append(end_date)
        if portfolio_tag:
            query += " AND r.portfolio_tag = ?"
            params.append(portfolio_tag)
        
        query += " ORDER BY r.rec_date DESC LIMIT ?"
        params.append(limit)
        
        try:
            cursor.execute(query, params)
        except sqlite3.OperationalError as e:
            if "no such column" in str(e).lower() or "no such table" in str(e).lower():
                init_blogger_tables()
                cursor.execute(query, params)
            else:
                raise
        return [dict(row) for row in cursor.fetchall()]


def delete_recommendation(rec_id):
    """åˆ é™¤æ¨èè®°å½•"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("DELETE FROM recommendations WHERE id = ?", (rec_id,))
        return cursor.rowcount


def get_blogger_stats(blogger_id=None):
    """è·å–åšä¸»ç»Ÿè®¡ä¿¡æ¯ (æ¨èæ•°é‡ã€æ¶µç›–æ—¥æœŸèŒƒå›´)"""
    with get_db() as conn:
        cursor = conn.cursor()
        
        if blogger_id:
            cursor.execute("""
                SELECT b.id, b.name, b.platform,
                       COUNT(r.id) as rec_count,
                       MIN(r.rec_date) as first_rec,
                       MAX(r.rec_date) as last_rec
                FROM bloggers b
                LEFT JOIN recommendations r ON b.id = r.blogger_id
                WHERE b.id = ?
                GROUP BY b.id
            """, (blogger_id,))
        else:
            cursor.execute("""
                SELECT b.id, b.name, b.platform,
                       COUNT(r.id) as rec_count,
                       MIN(r.rec_date) as first_rec,
                       MAX(r.rec_date) as last_rec
                FROM bloggers b
                LEFT JOIN recommendations r ON b.id = r.blogger_id
                GROUP BY b.id
                ORDER BY rec_count DESC
            """)
        
        return [dict(row) for row in cursor.fetchall()]


if __name__ == "__main__":
    # åˆå§‹åŒ–æ•°æ®åº“
    init_db()
    init_blogger_tables()
    print(get_db_stats())
