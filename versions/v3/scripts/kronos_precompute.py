"""
Kronos é¢„è®¡ç®—è„šæœ¬
==================
ç‹¬ç«‹äº Streamlit è¿è¡Œï¼Œæå‰ä¸ºæŒ‡å®šè‚¡ç¥¨æ‰¹é‡è®¡ç®— Kronos é¢„æµ‹ç»“æœï¼Œ
å°†ç»“æœç¼“å­˜åˆ° SQLite æ•°æ®åº“ï¼Œç½‘é¡µç«¯ç›´æ¥è¯»å–å³å¯ç§’å¼€ã€‚

ç”¨æ³•:
    # é¢„æµ‹æŒ‡å®šè‚¡ç¥¨
    python scripts/kronos_precompute.py HIMS AAPL NVDA TSLA

    # é¢„æµ‹ä»Šæ—¥æ‰«æå‡ºçš„æ‰€æœ‰è‚¡ç¥¨ (å« BLUE ä¿¡å·)
    python scripts/kronos_precompute.py --from-scan

    # ä»…é¢„æµ‹æœ‰ BLUE ä¿¡å·çš„
    python scripts/kronos_precompute.py --from-scan --blue-only

    # æŒ‡å®šå¸‚åœº
    python scripts/kronos_precompute.py --from-scan --market CN

    # è·‘å…¨é‡ (ç¾è‚¡+Aè‚¡)
    python scripts/kronos_precompute.py --from-scan --market US --from-scan --market CN

    # æ€§èƒ½åŸºå‡†æµ‹è¯• (åªè·‘å‰ N åª)
    python scripts/kronos_precompute.py --from-scan --benchmark 50
"""
import os
import sys
import json
import sqlite3
import argparse
import time
from datetime import datetime

# ç¡®ä¿é¡¹ç›®è·¯å¾„
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
V3_DIR = os.path.dirname(SCRIPT_DIR)
if V3_DIR not in sys.path:
    sys.path.insert(0, V3_DIR)

from ml.kronos_integration import get_kronos_engine
from ml.data_cache import DataCache

# é¢„æµ‹ç»“æœç¼“å­˜æ•°æ®åº“
CACHE_DB = os.path.join(V3_DIR, "db", "kronos_cache.db")


def init_cache_db():
    """åˆå§‹åŒ–ç¼“å­˜æ•°æ®åº“è¡¨"""
    os.makedirs(os.path.dirname(CACHE_DB), exist_ok=True)
    conn = sqlite3.connect(CACHE_DB)
    conn.execute("""
        CREATE TABLE IF NOT EXISTS kronos_predictions (
            symbol TEXT NOT NULL,
            market TEXT NOT NULL DEFAULT 'US',
            pred_date TEXT NOT NULL,
            pred_len INTEGER NOT NULL DEFAULT 20,
            temperature REAL NOT NULL DEFAULT 0.5,
            prediction_json TEXT NOT NULL,
            last_hist_date TEXT,
            last_hist_close REAL,
            created_at TEXT NOT NULL,
            PRIMARY KEY (symbol, market, pred_date, pred_len)
        )
    """)
    conn.commit()
    conn.close()


def save_prediction(symbol: str, market: str, pred_df, last_hist_date: str, last_hist_close: float,
                    pred_len: int = 20, temperature: float = 0.5):
    """ä¿å­˜é¢„æµ‹ç»“æœåˆ°ç¼“å­˜æ•°æ®åº“"""
    conn = sqlite3.connect(CACHE_DB)
    today = datetime.now().strftime("%Y-%m-%d")
    
    pred_records = []
    for idx, row in pred_df.iterrows():
        pred_records.append({
            "date": str(idx)[:10],
            "Open": round(float(row["Open"]), 4),
            "High": round(float(row["High"]), 4),
            "Low": round(float(row["Low"]), 4),
            "Close": round(float(row["Close"]), 4),
            "Volume": round(float(row["Volume"]), 2),
        })
    
    conn.execute("""
        INSERT OR REPLACE INTO kronos_predictions 
        (symbol, market, pred_date, pred_len, temperature, prediction_json, last_hist_date, last_hist_close, created_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
    """, (symbol, market, today, pred_len, temperature, json.dumps(pred_records),
          last_hist_date, last_hist_close, datetime.now().isoformat()))
    conn.commit()
    conn.close()


def load_prediction(symbol: str, market: str = "US", pred_date: str = None):
    """ä»ç¼“å­˜æ•°æ®åº“è¯»å–é¢„æµ‹ç»“æœ"""
    import pandas as pd
    if not os.path.exists(CACHE_DB):
        return None
    if pred_date is None:
        pred_date = datetime.now().strftime("%Y-%m-%d")
    
    conn = sqlite3.connect(CACHE_DB)
    row = conn.execute("""
        SELECT prediction_json, last_hist_date, last_hist_close, temperature, pred_len, created_at
        FROM kronos_predictions 
        WHERE symbol=? AND market=? AND pred_date=?
        ORDER BY created_at DESC LIMIT 1
    """, (symbol, market, pred_date)).fetchone()
    conn.close()
    
    if row is None:
        return None
    
    pred_records = json.loads(row[0])
    pred_df = pd.DataFrame(pred_records)
    pred_df.index = pd.to_datetime(pred_df["date"])
    pred_df.drop(columns=["date"], inplace=True)
    
    return {
        "pred_df": pred_df,
        "last_hist_date": row[1],
        "last_hist_close": float(row[2]),
        "temperature": float(row[3]),
        "pred_len": int(row[4]),
        "created_at": row[5],
    }


def get_scan_symbols(market: str = "US", blue_only: bool = False) -> list:
    """ä»æœ€è¿‘ä¸€æ¬¡æ‰«æç»“æœä¸­æå–è‚¡ç¥¨ä»£ç """
    db_path = os.path.join(V3_DIR, "db", "coral_creek.db")
    if not os.path.exists(db_path):
        print(f"  âš ï¸ æ•°æ®åº“ä¸å­˜åœ¨: {db_path}")
        return []
    conn = sqlite3.connect(db_path)
    
    # æŸ¥æ‰¾æœ€è¿‘çš„æ‰«ææ—¥æœŸ
    latest = conn.execute("""
        SELECT MAX(scan_date) FROM scan_results WHERE market=?
    """, (market,)).fetchone()[0]
    
    if latest is None:
        conn.close()
        return []
    
    if blue_only:
        rows = conn.execute("""
            SELECT DISTINCT symbol FROM scan_results 
            WHERE scan_date = ? AND market = ? AND blue_daily > 0
            ORDER BY symbol
        """, (latest, market)).fetchall()
    else:
        rows = conn.execute("""
            SELECT DISTINCT symbol FROM scan_results 
            WHERE scan_date = ? AND market = ?
            ORDER BY symbol
        """, (latest, market)).fetchall()
    conn.close()
    print(f"  ğŸ“¡ [{market}] æ‰«ææ—¥æœŸ {latest}, æ‰¾åˆ° {len(rows)} åªè‚¡ç¥¨" + (" (ä»…BLUE)" if blue_only else ""))
    return [r[0] for r in rows]


def predict_single(engine, cache, symbol: str, market: str = "US", pred_len: int = 20, temperature: float = 0.5):
    """å¯¹å•åªè‚¡ç¥¨è¿è¡Œ Kronos é¢„æµ‹å¹¶ç¼“å­˜"""
    import pandas as pd
    
    df = cache.get_stock_history(symbol, market=market)
    
    if df is None or len(df) < 60:
        return False, 0.0
    
    # å‡†å¤‡è¾“å…¥
    df_input = df.copy()
    df_input.columns = [c.lower() for c in df_input.columns]
    if "date" in df_input.columns:
        df_input.rename(columns={"date": "timestamps"}, inplace=True)
    df_input = df_input.tail(400)
    
    t0 = time.time()
    pred_df = engine.predict_future_klines(df_input, pred_len=pred_len, temperature=temperature, top_p=0.8)
    elapsed = time.time() - t0
    
    if pred_df is None:
        return False, elapsed
    
    # ä¿å­˜
    last_close = float(df_input["close"].iloc[-1])
    last_date = str(df_input["timestamps"].iloc[-1])[:10] if "timestamps" in df_input.columns else "unknown"
    save_prediction(symbol, market, pred_df, last_date, last_close, pred_len, temperature)
    
    pred_chg = (float(pred_df["Close"].iloc[-1]) / last_close - 1) * 100
    direction = "ğŸ“ˆ" if pred_chg > 0 else "ğŸ“‰"
    print(f"  âœ… {symbol} ({elapsed:.1f}s) {direction} {pred_chg:+.2f}%")
    return True, elapsed


def main():
    parser = argparse.ArgumentParser(description="Kronos æ‰¹é‡é¢„è®¡ç®—")
    parser.add_argument("symbols", nargs="*", help="è¦é¢„æµ‹çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨")
    parser.add_argument("--from-scan", action="store_true", help="ä»æœ€è¿‘ä¸€æ¬¡æ‰«æç»“æœä¸­æå–")
    parser.add_argument("--blue-only", action="store_true", help="ä»…é¢„æµ‹æœ‰ BLUE ä¿¡å·çš„è‚¡ç¥¨")
    parser.add_argument("--market", default="US", help="å¸‚åœº (US/CN)")
    parser.add_argument("--pred-len", type=int, default=20, help="é¢„æµ‹å¤©æ•°")
    parser.add_argument("--temperature", type=float, default=0.5, help="éšæœºåº¦")
    parser.add_argument("--benchmark", type=int, default=0, help="åŸºå‡†æµ‹è¯•æ¨¡å¼: åªè·‘å‰ N åª")
    args = parser.parse_args()
    
    symbols = list(args.symbols)
    
    if args.from_scan:
        scan_symbols = get_scan_symbols(args.market, args.blue_only)
        symbols = list(set(symbols + scan_symbols))
    
    if not symbols:
        symbols = ["HIMS", "AAPL", "NVDA", "TSLA", "PLTR"]
        print(f"â„¹ï¸ æœªæŒ‡å®šè‚¡ç¥¨, ä½¿ç”¨é»˜è®¤åˆ—è¡¨: {symbols}")
    
    if args.benchmark > 0:
        symbols = symbols[:args.benchmark]
        print(f"âš¡ åŸºå‡†æµ‹è¯•æ¨¡å¼: åªå¤„ç†å‰ {args.benchmark} åª")
    
    print(f"\nğŸª Kronos æ‰¹é‡é¢„è®¡ç®—å¯åŠ¨")
    print(f"   å¸‚åœº: {args.market}")
    print(f"   è‚¡ç¥¨æ•°é‡: {len(symbols)}")
    print(f"   é¢„æµ‹å¤©æ•°: {args.pred_len}")
    print(f"   æ¸©åº¦å‚æ•°: {args.temperature}")
    print(f"   ç¼“å­˜è·¯å¾„: {CACHE_DB}")
    print()
    
    # åˆå§‹åŒ–
    init_cache_db()
    cache = DataCache()
    
    print("ğŸš€ åŠ è½½ Kronos å¤§æ¨¡å‹å¼•æ“...")
    t_engine = time.time()
    engine = get_kronos_engine()
    engine_time = time.time() - t_engine
    print(f"âœ… å¼•æ“åŠ è½½å®Œæˆ ({engine_time:.1f}s)\n")
    
    t_start = time.time()
    success = 0
    fail = 0
    skip = 0
    times = []
    
    for i, sym in enumerate(symbols, 1):
        try:
            ok, elapsed = predict_single(engine, cache, sym, args.market, args.pred_len, args.temperature)
            if ok:
                success += 1
                times.append(elapsed)
            else:
                skip += 1
        except Exception as e:
            print(f"  âŒ {sym}: {e}")
            fail += 1
        
        # æ¯ 50 åªè¾“å‡ºä¸€æ¬¡è¿›åº¦
        if i % 50 == 0:
            elapsed_total = time.time() - t_start
            avg = sum(times) / len(times) if times else 0
            eta = avg * (len(symbols) - i)
            print(f"\n--- è¿›åº¦: {i}/{len(symbols)} | æˆåŠŸ: {success} | è·³è¿‡: {skip} | å¤±è´¥: {fail} | "
                  f"å·²ç”¨: {elapsed_total:.0f}s | å¹³å‡: {avg:.2f}s/åª | é¢„è®¡å‰©ä½™: {eta:.0f}s ---\n")
    
    total_time = time.time() - t_start
    avg_time = sum(times) / len(times) if times else 0
    
    print(f"\n{'='*60}")
    print(f"ğŸ Kronos æ‰¹é‡é¢„è®¡ç®—å®Œæˆ!")
    print(f"   å¸‚åœº: {args.market}")
    print(f"   æˆåŠŸ: {success} | è·³è¿‡(æ•°æ®ä¸è¶³): {skip} | å¤±è´¥: {fail}")
    print(f"   æ¨ç†æ€»è€—æ—¶: {total_time:.1f}s ({total_time/60:.1f}min)")
    print(f"   å¼•æ“åŠ è½½è€—æ—¶: {engine_time:.1f}s")
    print(f"   å¹³å‡æ¯åª: {avg_time:.2f}s")
    if success > 0:
        print(f"   å…¨é‡é¢„ä¼° (500åª): {500 * avg_time:.0f}s ({500 * avg_time / 60:.1f}min)")
        print(f"   å…¨é‡é¢„ä¼° (1000åª): {1000 * avg_time:.0f}s ({1000 * avg_time / 60:.1f}min)")
    print(f"   ç»“æœå·²ä¿å­˜åˆ°: {CACHE_DB}")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()
