import pandas as pd
import numpy as np
import os
import sys
import json
import argparse
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
import time
from datetime import datetime

# å¯¼å…¥å·¥å…·æ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

try:
    from data_fetcher import get_stock_data, get_all_us_tickers, get_ticker_details
    from indicator_utils import calculate_blue_signal_series, calculate_heima_signal_series, calculate_kdj_series, calculate_volume_profile_metrics, calculate_atr_series, calculate_adx_series, analyze_elliott_wave_proxy, analyze_chanlun_proxy
except ImportError:
    # å…¼å®¹æ€§å¯¼å…¥
    from data_fetcher import get_stock_data, get_all_us_tickers, get_ticker_details
    from indicator_utils import calculate_blue_signal_series, calculate_heima_signal_series, calculate_kdj_series, calculate_volume_profile_metrics, calculate_atr_series
    
    # ç®€å•çš„ mock å‡½æ•°
    def analyze_elliott_wave_proxy(closes, highs, lows): return {'phase': 'N/A', 'desc': 'N/A'}
    def analyze_chanlun_proxy(closes, highs, lows): return {'signal': 'N/A', 'desc': 'N/A'}
        
    # æœ¬åœ°å®šä¹‰ calculate_adx_series å¦‚æœå¯¼å…¥å¤±è´¥
    def calculate_adx_series(high, low, close, period=14):
        high_s = pd.Series(high)
        low_s = pd.Series(low)
        tr = calculate_atr_series(high, low, close, period=1)
        up_move = high_s - high_s.shift(1)
        down_move = pd.Series(low).shift(1) - pd.Series(low)
        plus_dm = np.where((up_move > down_move) & (up_move > 0), up_move, 0)
        minus_dm = np.where((down_move > up_move) & (down_move > 0), down_move, 0)
        tr_smooth = pd.Series(tr).ewm(alpha=1/period, adjust=False).mean()
        plus_dm_smooth = pd.Series(plus_dm).ewm(alpha=1/period, adjust=False).mean()
        minus_dm_smooth = pd.Series(minus_dm).ewm(alpha=1/period, adjust=False).mean()
        tr_smooth = tr_smooth.replace(0, np.nan)
        plus_di = 100 * (plus_dm_smooth / tr_smooth)
        minus_di = 100 * (minus_dm_smooth / tr_smooth)
        dx = 100 * np.abs(plus_di - minus_di) / (plus_di + minus_di)
        dx = dx.fillna(0)
        adx = dx.ewm(alpha=1/period, adjust=False).mean()
        return adx.values

def analyze_stock(symbol, market='US', account_size=100000):
    """
    æ·±åº¦åˆ†æå•åªè‚¡ç¥¨ï¼šè®¡ç®—ä¿¡å·ã€ç­–ç•¥åŒ¹é…ã€é£æ§å»ºè®®
    """
    try:
        # 1. è·å–æ•°æ® (10å¹´æ•°æ®ä»¥ç¡®ä¿æœˆçº¿æŒ‡æ ‡å……åˆ†æ”¶æ•›)
        df = get_stock_data(symbol, market, days=3650)
        if df is None or len(df) < 60:
            return None

        # 2. è®¡ç®—æŒ‡æ ‡
        opens = df['Open'].values
        highs = df['High'].values
        lows = df['Low'].values
        closes = df['Close'].values
        volumes = df['Volume'].values
        
        # åŸºç¡€æŒ‡æ ‡
        day_blue = calculate_blue_signal_series(opens, highs, lows, closes)
        heima, juedi = calculate_heima_signal_series(highs, lows, closes, opens)
        atr = calculate_atr_series(highs, lows, closes, period=14)
        adx = calculate_adx_series(highs, lows, closes)
        
        # è·å–æœ€æ–°ä¸€å¤©çš„å€¼
        curr_blue = day_blue[-1]
        curr_heima = heima[-1]
        curr_juedi = juedi[-1]
        curr_atr = atr[-1]
        curr_adx = adx[-1]
        curr_price = closes[-1]
        curr_vol = volumes[-1] * curr_price # æˆäº¤é¢
        
        # 3. æ·±åº¦ä½“æ£€ (æå‰è®¡ç®—ä»¥ç¡®å®šè‡ªé€‚åº”é˜ˆå€¼)
        log_ret = np.log(pd.Series(closes) / pd.Series(closes).shift(1))
        volatility = log_ret.tail(252).std() * np.sqrt(252) if len(log_ret) > 252 else 0.3 # é»˜è®¤ä¸­ç­‰
        
        # è‡ªé€‚åº”é˜ˆå€¼åˆ¤å®š V2.0 (åŸºäº Grid Search æ•°æ®ä¼˜åŒ–)
        adaptive_threshold = 100 # é»˜è®¤æ ‡å‡†
        regime_desc = "Standard"
        
        # è§„åˆ™ 1: ä¸­ä½æ³¢åŠ¨ (NVDA, TSLA, META çº§åˆ«) -> 80 æ˜¯é»„é‡‘åˆ†å‰²ç‚¹
        if volatility < 0.35:
            adaptive_threshold = 80
            regime_desc = "Mid-Low Vol"
            
        # è§„åˆ™ 2: æä½æ³¢åŠ¨ (AAPL, GOOGL, KO çº§åˆ«) -> å¿…é¡»æ”¾å®½åˆ° 60
        if volatility < 0.20:
            adaptive_threshold = 60
            regime_desc = "Low Vol (ç¨³å¥)"
            
        # è§„åˆ™ 3: å¼ºè¶‹åŠ¿ (Trend Following) -> åªè¦åœ¨è¶‹åŠ¿ä¸­ï¼Œ80 å³å¯ç¡®è®¤
        if curr_adx > 25:
            adaptive_threshold = min(adaptive_threshold, 80)
            regime_desc += " | å¼ºè¶‹åŠ¿"
            
        # è§„åˆ™ 4: å¦–è‚¡ (High Vol) -> å¿…é¡»å¼ºåŠ›çªç ´æ‰ç®—
        if volatility > 0.60:
            adaptive_threshold = 110
            regime_desc = "High Vol (å¦–è‚¡)"
            
        # 4. ç­–ç•¥åˆ¤å®š
        
        # [Strategy D] æ¿€è¿›è¶‹åŠ¿: ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼
        is_strat_d = (curr_blue > adaptive_threshold)
        
        # [Strategy C] å®½æ¾å…±æŒ¯: (BLUE OR Heima) + Context
        recent_blues = day_blue[-5:]
        recent_heimas = (heima[-5:] | juedi[-5:])
        
        # å…±æŒ¯ä¸­çš„ BLUE ä¹Ÿä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼
        has_recent_blue = np.any(recent_blues > adaptive_threshold)
        has_recent_heima = np.any(recent_heimas)
        
        is_strat_c = False
        if (curr_blue > adaptive_threshold and has_recent_heima) or ((curr_heima or curr_juedi) and has_recent_blue):
            is_strat_c = True
            
        # [Legacy] æ—§ç‰ˆä¿¡å·: ä¸¥æ ¼ 100
        is_legacy = (curr_blue > 100)
        
        # å¦‚æœæ²¡æœ‰ä»»ä½•ç­–ç•¥å‘½ä¸­ï¼Œç›´æ¥è¿”å› None (èŠ‚çœç©ºé—´)
        if not (is_strat_d or is_strat_c):
            return None
            
        # é£æ§å‚æ•°è®¡ç®—
        stop_mult = 2.0
        risk_pct = 0.02
        
        if "High Vol" in regime_desc:
            stop_mult = 3.5
            risk_pct = 0.01
        elif "Low Vol" in regime_desc:
            stop_mult = 1.8
            risk_pct = 0.03
            
        if curr_adx > 30:
            stop_mult += 0.5 # è¶‹åŠ¿ä¸­æ”¾å®½æ­¢æŸ
            
        # å‘¨çº¿ç¡®è®¤ (Optional Context)
        df_weekly = df.resample('W-FRI').agg({
            'Open': 'first', 'High': 'max', 'Low': 'min', 'Close': 'last'
        }).dropna()
        week_blue_val = 0
        if len(df_weekly) >= 10:  # è‡³å°‘éœ€è¦10å‘¨æ•°æ®
            w_blue = calculate_blue_signal_series(
                df_weekly['Open'].values, df_weekly['High'].values, 
                df_weekly['Low'].values, df_weekly['Close'].values
            )
            week_blue_val = w_blue[-1] if len(w_blue) > 0 else 0
        
        # æœˆçº¿ç¡®è®¤ (é•¿æœŸè¶‹åŠ¿)
        df_monthly = df.resample('ME').agg({  # 'ME' = Month End
            'Open': 'first', 'High': 'max', 'Low': 'min', 'Close': 'last'
        }).dropna()
        month_blue_val = 0
        if len(df_monthly) >= 6:  # è‡³å°‘éœ€è¦6ä¸ªæœˆæ•°æ®
            m_blue = calculate_blue_signal_series(
                df_monthly['Open'].values, df_monthly['High'].values, 
                df_monthly['Low'].values, df_monthly['Close'].values
            )
            month_blue_val = m_blue[-1] if len(m_blue) > 0 else 0
            
        # Volume Profile (VP)
        vp_res = calculate_volume_profile_metrics(closes, volumes, curr_price)
        vp_rating = "Normal"
        if vp_res['profit_ratio'] > 0.9: vp_rating = "Excellent"
        elif vp_res['profit_ratio'] < 0.1: vp_rating = "Poor"
        elif vp_res['price_pos'] == 'Above': vp_rating = "Good"
        
        # 5. æ³¢æµªå½¢æ€è¯†åˆ« (Elliott Wave Proxy)
        wave_res = analyze_elliott_wave_proxy(closes, highs, lows)
        
        # 6. ç¼ è®ºå½¢æ€è¯†åˆ« (Chanlun Proxy)
        chan_res = analyze_chanlun_proxy(closes, highs, lows)
        
        # 7. è·å–å¸‚å€¼å¹¶åˆ†ç±» (ä»…å¯¹å…¥é€‰è‚¡ç¥¨è¿›è¡Œï¼ŒèŠ‚çœAPI)
        market_cap = 0
        shares_outstanding = 0
        cap_category = "Unknown"
        company_name = symbol
        industry = "Unknown"
        
        try:
            if market == 'US':
                # ç¾è‚¡: ä½¿ç”¨ Polygon API
                details = get_ticker_details(symbol)
                if details:
                    market_cap = details.get('market_cap', 0)
                    shares_outstanding = details.get('shares_outstanding', 0)
                    company_name = details.get('name', symbol)
                    industry = details.get('sic_description', 'Unknown')
                    
                    # å¦‚æœ API æ²¡è¿”å›å¸‚å€¼ï¼Œå°è¯•ç”¨ Price * Shares ä¼°ç®—
                    if market_cap == 0 and shares_outstanding > 0:
                        market_cap = curr_price * shares_outstanding
            else:
                # Aè‚¡: å°è¯•ä»å…¨å±€ç¼“å­˜è·å– (åœ¨ scan_all_stocks ä¸­é¢„åŠ è½½)
                global _cn_market_cap_cache
                if '_cn_market_cap_cache' not in dir() or _cn_market_cap_cache is None:
                    _cn_market_cap_cache = {}
                
                code = symbol.split('.')[0]
                if code in _cn_market_cap_cache:
                    market_cap = _cn_market_cap_cache[code].get('market_cap', 0)
                    company_name = _cn_market_cap_cache[code].get('name', symbol)
                    industry = _cn_market_cap_cache[code].get('industry', 'Unknown')
            
            # åˆ†ç±»é€»è¾‘
            if market_cap > 200_000_000_000: # 200B
                cap_category = "Mega-Cap (å·¨å¤´)"
            elif market_cap > 10_000_000_000: # 10B
                cap_category = "Large-Cap (å¤§ç›˜)"
            elif market_cap > 2_000_000_000: # 2B
                cap_category = "Mid-Cap (ä¸­ç›˜)"
            elif market_cap > 300_000_000: # 300M
                cap_category = "Small-Cap (å°ç›˜)"
            elif market_cap > 0:
                cap_category = "Micro-Cap (å¾®ç›˜)"
        except:
            pass
        
        # 8. é£æ§å»ºè®®
        stop_loss_price = curr_price - (stop_mult * curr_atr)
        risk_amt = account_size * risk_pct
        shares = int(risk_amt / (stop_mult * curr_atr)) if curr_atr > 0 else 0
        
        return {
            'Symbol': symbol,
            'Price': curr_price,
            'Turnover_M': round(curr_vol / 1000000, 2),
            'Date': df.index[-1].strftime('%Y-%m-%d'),
            
            # ä¿¡å·
            'Blue_Daily': round(curr_blue, 1),
            'Adaptive_Thresh': adaptive_threshold, # æ˜¾ç¤ºå½“å‰ç”¨çš„é˜ˆå€¼
            'Blue_Weekly': round(week_blue_val, 1),
            'Blue_Monthly': round(month_blue_val, 1),
            'Is_Heima': curr_heima or curr_juedi,
            
            # ç­–ç•¥æ ‡ç­¾
            'Strat_D_Trend': is_strat_d,
            'Strat_C_Resonance': is_strat_c,
            'Legacy_Signal': is_legacy,
            
            # æ·±åº¦åˆ†æ
            'Regime': regime_desc,
            'Volatility': round(volatility, 2),
            'ADX': round(curr_adx, 1),
            'VP_Rating': vp_rating,
            'Profit_Ratio': vp_res['profit_ratio'],
            'Wave_Phase': wave_res['phase'],
            'Wave_Desc': wave_res['desc'],
            'Chan_Signal': chan_res['signal'],
            'Chan_Desc': chan_res['desc'],
            
            # åŸºæœ¬é¢
            'Market_Cap': market_cap,
            'Cap_Category': cap_category,
            'Company_Name': company_name,
            'Industry': industry,
            
            # æ‰§è¡Œå»ºè®®
            'Stop_Loss': round(stop_loss_price, 2),
            'Shares_Rec': shares, # åŸºäº10Wè´¦æˆ·
            'Risk_Reward_Score': round(curr_adx * (1-volatility), 2)
        }
        
    except Exception as e:
        # print(f"Error analyzing {symbol}: {e}")
        return None

def main():
    parser = argparse.ArgumentParser(description='Enhanced Stock Scanner V2.0')
    parser.add_argument('--limit', type=int, default=0, help='Limit number of tickers (0 for all)')
    parser.add_argument('--workers', type=int, default=20, help='Parallel workers')
    parser.add_argument('--market', type=str, default='US', help='Market (US/CN)')
    args = parser.parse_args()
    
    print(f"ğŸš€ Starting Enhanced Scan (Market: {args.market})...")
    print(f"âš™ï¸  Strategy: Adaptive Thresholds & Risk Management")
    
    # 1. è·å–è‚¡ç¥¨åˆ—è¡¨
    if args.market == 'US':
        tickers = get_all_us_tickers()
        if not tickers:
            print("Failed to fetch tickers.")
            return
    else:
        print("CN market not fully supported in auto-fetch yet.")
        return

    if args.limit > 0:
        tickers = tickers[:args.limit]
        
    print(f"ğŸ“‹ Scanning {len(tickers)} stocks...")
    
    results = []
    start_time = time.time()
    
    # 2. å¹¶å‘æ‰«æ
    with ThreadPoolExecutor(max_workers=args.workers) as executor:
        future_to_symbol = {executor.submit(analyze_stock, symbol, args.market): symbol for symbol in tickers}
        
        for future in tqdm(as_completed(future_to_symbol), total=len(tickers), unit="stock"):
            res = future.result()
            if res:
                results.append(res)
                
    elapsed = time.time() - start_time
    print(f"\nâœ… Scan complete in {elapsed:.1f}s. Found {len(results)} candidates.")
    
    if not results:
        print("No signals found.")
        return
        
    # 3. ä¿å­˜ç»“æœ
    df = pd.DataFrame(results)
    
    # æ’åºï¼šä¼˜å…ˆå±•ç¤º Strat C (å…±æŒ¯)ï¼Œç„¶åæŒ‰ ADX æ’åº
    df.sort_values(by=['Strat_C_Resonance', 'ADX'], ascending=[False, False], inplace=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"enhanced_scan_results_{args.market}_{timestamp}.csv"
    output_path = os.path.join(current_dir, filename)
    
    df.to_csv(output_path, index=False)
    print(f"ğŸ’¾ Results saved to: {filename}")
    
    # 4. æ‰“å°ç²¾åé¢„è§ˆ (Top 10)
    print("\nğŸ† Top 10 Candidates (Sorted by Resonance & Trend):")
    # æ˜¾ç¤º Adaptive Thresh ä»¥ä¾¿éªŒè¯
    cols = ['Symbol', 'Price', 'Blue_Daily', 'Adaptive_Thresh', 'Strat_D_Trend', 'Regime', 'Shares_Rec']
    print(df[cols].head(10).to_string(index=False))

if __name__ == "__main__":
    main()
