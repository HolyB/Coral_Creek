#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ğŸ“° æ–°é—»æ™ºèƒ½ä¸­å¿ƒ (v2)
====================
å¤šæºæ–°é—» + ç¤¾äº¤åª’ä½“ + AI åˆ†æ
"""
import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
from typing import List, Dict

# å¯¼å…¥æ–°é—»ç³»ç»Ÿ
try:
    from news import NewsIntelligence, get_news_intelligence
    from news.models import EventType, Sentiment, NewsDigest
    from news.crawler import (
        get_news_crawler, StockTwitsCrawler, ApeWisdomCrawler
    )
    NEWS_AVAILABLE = True
except ImportError as e:
    NEWS_AVAILABLE = False
    print(f"News module not available: {e}")


def render_news_center_page():
    """æ¸²æŸ“æ–°é—»ä¸­å¿ƒé¡µé¢"""
    st.title("ğŸ“° æ–°é—»æ™ºèƒ½ä¸­å¿ƒ")
    st.caption("å¤šæºæ–°é—»èšåˆ + ç¤¾äº¤åª’ä½“æƒ…ç»ª + AI åˆ†æ | Google News Â· yfinance Â· StockTwits Â· Reddit")
    
    if not NEWS_AVAILABLE:
        st.error("âŒ æ–°é—»æ¨¡å—æœªæ­£ç¡®åŠ è½½")
        return
    
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ” ä¸ªè‚¡æ–°é—»",
        "ğŸ”¥ ç¤¾äº¤çƒ­åº¦",
        "ğŸ“Š æŒä»“æ–°é—»",
        "ğŸ“ˆ è¶‹åŠ¿å‘ç°",
    ])
    
    with tab1:
        _render_single_stock_tab()
    with tab2:
        _render_social_buzz_tab()
    with tab3:
        _render_portfolio_news_tab()
    with tab4:
        _render_trending_tab()


def _render_single_stock_tab():
    """ä¸ªè‚¡æ–°é—»åˆ†æ â€” å¤šæº + AI åˆ†ç±»"""
    
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1:
        symbol = st.text_input("è‚¡ç¥¨ä»£ç ", value="NVDA", placeholder="å¦‚ AAPL, TSLA, 600519.SH",
                               key="news_symbol")
    with col2:
        market = st.selectbox("å¸‚åœº", ["US", "CN"], index=0, key="news_market")
    with col3:
        use_llm = st.checkbox("ğŸ§  AI åˆ†ç±»", value=True, help="ç”¨ Gemini æ‰¹é‡åˆ†ç±»",
                              key="news_llm")
    
    if st.button("ğŸ” åˆ†ææ–°é—»", type="primary", use_container_width=True, key="news_analyze"):
        if not symbol:
            st.warning("è¯·è¾“å…¥è‚¡ç¥¨ä»£ç ")
            return
        
        with st.spinner(f"æ­£åœ¨ä»å¤šä¸ªæ¥æºæŠ“å– {symbol.upper()} çš„æ–°é—»..."):
            try:
                intel = get_news_intelligence(use_llm=use_llm)
                events, impacts, digest = intel.analyze_symbol(
                    symbol.upper(), market=market
                )
                
                if not events:
                    st.info(f"ğŸ“­ æš‚æ—  {symbol} ç›¸å…³æ–°é—»")
                    return
                
                # ç¼“å­˜ç»“æœ
                st.session_state['news_events'] = events
                st.session_state['news_impacts'] = impacts
                st.session_state['news_digest'] = digest
                st.session_state['news_current_symbol'] = symbol.upper()
                
            except Exception as e:
                st.error(f"åˆ†æå¤±è´¥: {e}")
                import traceback
                st.code(traceback.format_exc())
                return
    
    # æ˜¾ç¤ºç¼“å­˜çš„ç»“æœ
    events = st.session_state.get('news_events')
    impacts = st.session_state.get('news_impacts')
    digest = st.session_state.get('news_digest')
    current_symbol = st.session_state.get('news_current_symbol', '')
    
    if events and digest:
        _render_digest_card(digest, current_symbol)
        st.divider()
        
        # æŒ‰æ¥æºç»Ÿè®¡
        sources = {}
        for e in events:
            src = e.source.split('@')[0].strip() if '@' in e.source else e.source
            sources[src] = sources.get(src, 0) + 1
        
        source_str = " Â· ".join([f"`{k}` Ã—{v}" for k, v in sorted(
            sources.items(), key=lambda x: -x[1]
        )[:5]])
        st.caption(f"ğŸ“¡ æ•°æ®æ¥æº: {source_str}")
        
        # æ–°é—»åˆ—è¡¨
        st.subheader(f"ğŸ“‹ æ–°é—»è¯¦æƒ… ({len(events)} æ¡)")
        
        # è¿‡æ»¤å™¨
        fcol1, fcol2 = st.columns(2)
        with fcol1:
            event_types = list(set(e.event_type.chinese_name for e in events))
            filter_type = st.multiselect("äº‹ä»¶ç±»å‹", event_types, default=event_types,
                                         key="news_filter_type")
        with fcol2:
            sentiments = ["å…¨éƒ¨", "ğŸ‚ åˆ©å¥½", "ğŸ» åˆ©ç©º", "â– ä¸­æ€§"]
            filter_sent = st.selectbox("æƒ…ç»ª", sentiments, key="news_filter_sent")
        
        for i, (event, impact) in enumerate(zip(events, impacts)):
            # è¿‡æ»¤
            if event.event_type.chinese_name not in filter_type:
                continue
            if filter_sent == "ğŸ‚ åˆ©å¥½" and event.sentiment.score <= 0:
                continue
            if filter_sent == "ğŸ» åˆ©ç©º" and event.sentiment.score >= 0:
                continue
            if filter_sent == "â– ä¸­æ€§" and event.sentiment.score != 0:
                continue
            
            _render_news_card(event, impact, i)


def _render_digest_card(digest, symbol: str):
    """æ¸²æŸ“æ–°é—»æ‘˜è¦å¡ç‰‡"""
    sentiment_ratio = digest.sentiment_ratio()
    
    if sentiment_ratio > 0.3:
        color, emoji, text = "#00C853", "ğŸŸ¢", "çœ‹æ¶¨"
    elif sentiment_ratio < -0.3:
        color, emoji, text = "#FF1744", "ğŸ”´", "çœ‹è·Œ"
    else:
        color, emoji, text = "#FFD600", "âšª", "ä¸­æ€§"
    
    # ä¸»å¡ç‰‡
    st.markdown(f"""
    <div style="background: linear-gradient(135deg, {color}15, {color}08);
                border-left: 4px solid {color}; padding: 16px; border-radius: 10px;">
        <div style="display: flex; align-items: center; gap: 16px;">
            <div>
                <span style="font-size: 2em;">{emoji}</span>
            </div>
            <div style="flex: 1;">
                <h3 style="margin: 0; color: {color};">{symbol} â€” {text}</h3>
                <span style="color: #b0b0b0;">
                    ğŸ“° {digest.total_news_count} æ¡æ–°é—» Â· 
                    ğŸ‚ {digest.bullish_count} åˆ©å¥½ Â· 
                    ğŸ» {digest.bearish_count} åˆ©ç©º Â· 
                    â– {digest.neutral_count} ä¸­æ€§
                </span>
            </div>
            <div style="text-align: center;">
                <div style="font-size: 1.5em; font-weight: bold; color: {color};">
                    {digest.avg_expected_impact:+.1f}%
                </div>
                <div style="font-size: 0.8em; color: #8b949e;">é¢„æœŸå½±å“</div>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    if digest.key_events:
        st.info("ğŸ”‘ **å…³é”®äº‹ä»¶:** " + " | ".join(digest.key_events[:3]))


def _render_news_card(event, impact, index: int):
    """æ¸²æŸ“å•æ¡æ–°é—»å¡ç‰‡"""
    
    sentiment_icons = {
        Sentiment.VERY_BULLISH: "ğŸ”¥",
        Sentiment.BULLISH: "ğŸ“ˆ",
        Sentiment.NEUTRAL: "â–",
        Sentiment.BEARISH: "ğŸ“‰",
        Sentiment.VERY_BEARISH: "ğŸ’¥",
    }
    icon = sentiment_icons.get(event.sentiment, "â–")
    
    # æ¥æºæ ‡è®°
    source_badges = {
        'StockTwits': 'ğŸ’¬',
        'Yahoo': 'ğŸ“°',
        'Google': 'ğŸ”',
        'Finnhub': 'ğŸ“Š',
        'Polygon': 'ğŸ”·',
    }
    src_badge = "ğŸ“°"
    for key, badge in source_badges.items():
        if key.lower() in event.source.lower():
            src_badge = badge
            break
    
    title_display = event.title[:80] + ('...' if len(event.title) > 80 else '')
    
    with st.expander(
        f"{icon} {src_badge} **{title_display}**",
        expanded=(index == 0)
    ):
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.markdown(f"""
**ğŸ“Œ ç±»å‹:** {event.event_type.chinese_name}

**ğŸ“… æ—¶é—´:** {event.published_at.strftime('%Y-%m-%d %H:%M') if event.published_at else 'N/A'}

**ğŸ“° æ¥æº:** {event.source}
            """)
            
            if event.summary and event.summary != event.title:
                st.caption(f"ğŸ“ {event.summary[:200]}")
            
            if event.url:
                st.markdown(f"ğŸ”— [æŸ¥çœ‹åŸæ–‡]({event.url})")
        
        with col2:
            impact_color = "#00C853" if impact.expected_impact_pct > 0 else (
                "#FF1744" if impact.expected_impact_pct < 0 else "#FFD600"
            )
            st.markdown(f"""
<div style="text-align: center; background: {impact_color}15; 
            padding: 12px; border-radius: 8px;">
    <div style="font-size: 1.5em; font-weight: bold; color: {impact_color};">
        {impact.expected_impact_pct:+.1f}%
    </div>
    <div style="font-size: 0.8em; color: #8b949e;">é¢„æœŸå½±å“</div>
    <div style="margin-top: 4px;">ç½®ä¿¡åº¦: {impact.confidence:.0f}%</div>
    <div>ç´§æ€¥åº¦: {'ğŸ”¥' * impact.urgency}</div>
</div>
            """, unsafe_allow_html=True)
        
        if event.keywords:
            st.markdown("**ğŸ·ï¸ å…³é”®è¯:** " + " ".join([f"`{kw}`" for kw in event.keywords[:5]]))


def _render_social_buzz_tab():
    """ç¤¾äº¤åª’ä½“çƒ­åº¦ â€” StockTwits + Reddit"""
    
    st.subheader("ğŸ”¥ ç¤¾äº¤åª’ä½“çƒ­åº¦")
    
    col1, col2 = st.columns([2, 1])
    with col1:
        symbol = st.text_input("æŸ¥è¯¢è‚¡ç¥¨", value="NVDA", key="social_symbol")
    with col2:
        st.caption("")
        analyze = st.button("ğŸ“Š åˆ†æç¤¾äº¤çƒ­åº¦", type="primary", key="social_btn",
                           use_container_width=True)
    
    if analyze and symbol:
        with st.spinner(f"æ­£åœ¨åˆ†æ {symbol.upper()} çš„ç¤¾äº¤åª’ä½“..."):
            try:
                crawler = get_news_crawler()
                buzz = crawler.get_social_buzz(symbol.upper(), market='US')
                
                st.session_state['social_buzz'] = buzz
            except Exception as e:
                st.error(f"åˆ†æå¤±è´¥: {e}")
    
    buzz = st.session_state.get('social_buzz')
    if buzz:
        _render_buzz_card(buzz)
    
    # StockTwits è¶‹åŠ¿ (ç›´æ¥æ˜¾ç¤º)
    st.divider()
    st.subheader("ğŸ“ˆ StockTwits çƒ­é—¨")
    
    if st.button("ğŸ”„ åˆ·æ–°çƒ­é—¨", key="st_trending"):
        with st.spinner("è·å– StockTwits çƒ­é—¨..."):
            try:
                st_crawler = StockTwitsCrawler()
                trending = st_crawler.get_trending()
                st.session_state['st_trending'] = trending
            except Exception as e:
                st.error(f"è·å–å¤±è´¥: {e}")
    
    trending = st.session_state.get('st_trending')
    if trending and isinstance(trending, list):
        df = pd.DataFrame(trending)
        if not df.empty:
            st.dataframe(
                df[['symbol', 'title', 'watchlist_count']].rename(columns={
                    'symbol': 'ä»£ç ', 'title': 'åç§°', 'watchlist_count': 'å…³æ³¨æ•°'
                }),
                use_container_width=True, hide_index=True
            )
    
    # Reddit/WSB è¶‹åŠ¿
    st.divider()
    st.subheader("ğŸ¦ Reddit WallStreetBets çƒ­é—¨")
    
    if st.button("ğŸ”„ åˆ·æ–° WSB", key="wsb_trending"):
        with st.spinner("è·å– Reddit çƒ­é—¨..."):
            try:
                ape = ApeWisdomCrawler()
                wsb = ape.get_trending(filter_type="all-stocks", limit=15)
                st.session_state['wsb_trending'] = wsb
            except Exception as e:
                st.error(f"è·å–å¤±è´¥: {e}")
    
    wsb = st.session_state.get('wsb_trending')
    if wsb and isinstance(wsb, list):
        df = pd.DataFrame(wsb)
        if not df.empty:
            cols = ['rank', 'symbol', 'name', 'mentions', 'upvotes']
            cols = [c for c in cols if c in df.columns]
            st.dataframe(
                df[cols].rename(columns={
                    'rank': 'æ’å', 'symbol': 'ä»£ç ', 'name': 'åç§°',
                    'mentions': 'æåŠæ¬¡æ•°', 'upvotes': 'ç‚¹èµæ•°'
                }),
                use_container_width=True, hide_index=True
            )


def _render_buzz_card(buzz: Dict):
    """æ¸²æŸ“ç¤¾äº¤çƒ­åº¦å¡ç‰‡"""
    
    symbol = buzz.get('symbol', '')
    total_score = buzz.get('total_buzz_score', 0)
    
    # çƒ­åº¦ç­‰çº§
    if total_score > 100:
        heat = "ğŸ”¥ğŸ”¥ğŸ”¥ æé«˜"
        heat_color = "#FF1744"
    elif total_score > 50:
        heat = "ğŸ”¥ğŸ”¥ é«˜"
        heat_color = "#FF9100"
    elif total_score > 20:
        heat = "ğŸ”¥ ä¸­ç­‰"
        heat_color = "#FFD600"
    else:
        heat = "â„ï¸ ä½"
        heat_color = "#4FC3F7"
    
    st.markdown(f"""
    <div style="background: linear-gradient(135deg, {heat_color}15, {heat_color}08);
                border-left: 4px solid {heat_color}; padding: 16px; border-radius: 10px;">
        <h3 style="margin: 0; color: {heat_color};">
            {symbol} ç¤¾äº¤çƒ­åº¦: {heat}
        </h3>
        <span style="color: #8b949e;">ç»¼åˆè¯„åˆ†: {total_score}</span>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    # StockTwits
    st_data = buzz.get('stocktwits_sentiment')
    with col1:
        st.markdown("**ğŸ’¬ StockTwits**")
        if st_data:
            ratio = st_data.get('ratio', 0)
            ratio_color = "#00C853" if ratio > 0 else ("#FF1744" if ratio < 0 else "#FFD600")
            st.metric("è®¨è®ºæ•°", st_data.get('total', 0))
            st.metric("ğŸ‚ çœ‹å¤š", st_data.get('bullish', 0))
            st.metric("ğŸ» çœ‹ç©º", st_data.get('bearish', 0))
        else:
            st.caption("æš‚æ— æ•°æ®")
    
    # Reddit
    with col2:
        st.markdown("**ğŸ¦ Reddit**")
        rank = buzz.get('reddit_rank')
        mentions = buzz.get('reddit_mentions', 0)
        if rank:
            st.metric("WSB æ’å", f"#{rank}")
            st.metric("æåŠæ¬¡æ•°", mentions)
        else:
            st.caption("æœªè¿›å…¥çƒ­æ¦œ")
    
    # Finnhub
    fh = buzz.get('finnhub_social')
    with col3:
        st.markdown("**ğŸ“Š Finnhub ç¤¾äº¤**")
        if fh:
            st.metric("Reddit æåŠ (7å¤©)", fh.get('reddit_mentions_7d', 0))
            st.metric("Twitter æåŠ (7å¤©)", fh.get('twitter_mentions_7d', 0))
        else:
            st.caption("éœ€è¦ Finnhub API key")


def _render_portfolio_news_tab():
    """æŒä»“æ–°é—»åˆ†æ"""
    
    st.subheader("ğŸ“Š æŒä»“æ–°é—»åˆ†æ")
    
    default_portfolio = "NVDA, AAPL, MSFT, GOOGL, TSLA"
    portfolio_input = st.text_input(
        "è¾“å…¥æŒä»“ä»£ç  (é€—å·åˆ†éš”)", value=default_portfolio,
        key="portfolio_input"
    )
    
    col1, col2 = st.columns(2)
    with col1:
        market = st.selectbox("å¸‚åœº", ["US", "CN"], key="portfolio_market")
    with col2:
        use_llm = st.checkbox("ğŸ§  AI åˆ†ç±»", value=True, key="portfolio_llm")
    
    if st.button("ğŸ“Š åˆ†ææŒä»“", type="primary", use_container_width=True, key="portfolio_btn"):
        symbols = [s.strip().upper() for s in portfolio_input.split(",") if s.strip()]
        
        if not symbols:
            st.warning("è¯·è¾“å…¥è‚¡ç¥¨ä»£ç ")
            return
        
        intel = get_news_intelligence(use_llm=use_llm)
        progress = st.progress(0)
        all_digests = []
        all_alerts = []
        
        for i, symbol in enumerate(symbols):
            progress.progress((i + 1) / len(symbols), text=f"åˆ†æ {symbol}...")
            try:
                events, impacts, digest = intel.analyze_symbol(symbol, market=market)
                all_digests.append((symbol, digest))
                
                for event, impact in zip(events, impacts):
                    if impact.should_alert:
                        all_alerts.append({
                            'symbol': symbol,
                            'title': event.title[:60],
                            'type': event.event_type.chinese_name,
                            'sentiment': event.sentiment.emoji,
                            'impact': impact.expected_impact_pct,
                        })
            except Exception as e:
                st.warning(f"âš ï¸ {symbol}: {e}")
        
        progress.empty()
        
        if all_digests:
            st.subheader("ğŸ“‹ æŒä»“æ–°é—»æ‘˜è¦")
            
            rows = []
            for symbol, digest in all_digests:
                ratio = digest.sentiment_ratio()
                emoji = "ğŸŸ¢" if ratio > 0.3 else ("ğŸ”´" if ratio < -0.3 else "âšª")
                rows.append({
                    'è‚¡ç¥¨': symbol,
                    'æƒ…ç»ª': emoji,
                    'æ–°é—»æ•°': digest.total_news_count,
                    'åˆ©å¥½': digest.bullish_count,
                    'åˆ©ç©º': digest.bearish_count,
                    'é¢„æœŸå½±å“': f"{digest.avg_expected_impact:+.1f}%",
                    'ä¿¡å·è°ƒæ•´': f"{digest.signal_adjustment:.2f}x",
                })
            
            df = pd.DataFrame(rows)
            st.dataframe(df, use_container_width=True, hide_index=True)
        
        if all_alerts:
            st.subheader(f"ğŸš¨ éœ€è¦å…³æ³¨ ({len(all_alerts)} æ¡)")
            for alert in all_alerts[:10]:
                impact = alert['impact']
                icon = "ğŸ“ˆ" if impact > 0 else "ğŸ“‰"
                st.markdown(
                    f"**{alert['symbol']}** {icon} {alert['type']} {alert['sentiment']} "
                    f"â€” {alert['title']} ({impact:+.1f}%)"
                )


def _render_trending_tab():
    """è¶‹åŠ¿å‘ç° â€” æ•°æ®æºçŠ¶æ€"""
    
    st.subheader("ğŸ“ˆ è¶‹åŠ¿å‘ç°")
    
    # æ•°æ®æºçŠ¶æ€
    st.markdown("### ğŸ“¡ æ•°æ®æºçŠ¶æ€")
    
    import os
    sources = {
        'Google News RSS': ('âœ… å¯ç”¨', 'å…è´¹', 'å…¨çƒ'),
        'yfinance News': ('âœ… å¯ç”¨', 'å…è´¹', 'ç¾è‚¡'),
        'StockTwits API': ('âœ… å¯ç”¨', 'å…è´¹', 'ç¾è‚¡'),
        'ApeWisdom (Reddit/WSB)': ('âœ… å¯ç”¨', 'å…è´¹', 'ç¾è‚¡'),
        'Finnhub': (
            'âœ… å¯ç”¨' if os.getenv('FINNHUB_API_KEY') else 'âš ï¸ éœ€è¦ API Key',
            'å…è´¹ (60æ¬¡/åˆ†)', 'å…¨çƒ'
        ),
        'Polygon': (
            'âœ… å¯ç”¨' if os.getenv('POLYGON_API_KEY') else 'âš ï¸ éœ€è¦ API Key',
            'å…è´¹ (5æ¬¡/åˆ†)', 'ç¾è‚¡'
        ),
        'Gemini AI åˆ†ç±»': (
            'âœ… å¯ç”¨' if (os.getenv('GEMINI_API_KEY') or os.getenv('GOOGLE_API_KEY')) else 'âš ï¸ éœ€è¦ API Key',
            'å…è´¹é¢åº¦', 'å…¨çƒ'
        ),
    }
    
    rows = []
    for name, (status, cost, market) in sources.items():
        rows.append({
            'æ•°æ®æº': name,
            'çŠ¶æ€': status,
            'è´¹ç”¨': cost,
            'è¦†ç›–': market,
        })
    
    df = pd.DataFrame(rows)
    st.dataframe(df, use_container_width=True, hide_index=True)
    
    # API Key é…ç½®æç¤º
    st.markdown("### ğŸ”‘ é…ç½®æç¤º")
    st.info("""
**å¯é€‰ API Key é…ç½® (å…è´¹æ³¨å†Œ)ï¼š**
- `FINNHUB_API_KEY` â€” [æ³¨å†Œ Finnhub](https://finnhub.io/) â†’ 60 æ¬¡/åˆ†é’Ÿå…è´¹é¢åº¦
- `POLYGON_API_KEY` â€” [æ³¨å†Œ Polygon](https://polygon.io/) â†’ 5 æ¬¡/åˆ†é’Ÿå…è´¹é¢åº¦
- `GEMINI_API_KEY` â€” [æ³¨å†Œ Google AI](https://aistudio.google.com/) â†’ å…è´¹é¢åº¦
    
è®¾ç½®ä¸ºç¯å¢ƒå˜é‡æˆ– Streamlit secrets å³å¯ã€‚
    """)
    
    # å¿«é€Ÿæ–°é—»æµ‹è¯•
    st.divider()
    st.markdown("### ğŸ§ª å¿«é€Ÿæµ‹è¯•")
    test_symbol = st.text_input("æµ‹è¯•ä»£ç ", value="AAPL", key="test_symbol")
    if st.button("ğŸ§ª æµ‹è¯•æ‰€æœ‰æº", key="test_sources"):
        with st.spinner("æµ‹è¯•ä¸­..."):
            crawler = get_news_crawler()
            
            # Google
            gn = crawler.google.crawl(test_symbol, max_results=2)
            st.write(f"Google News: {len(gn)} æ¡")
            
            # yfinance
            yf_n = crawler.yfinance.crawl(test_symbol, max_results=2)
            st.write(f"yfinance: {len(yf_n)} æ¡")
            
            # StockTwits
            st_n = crawler.stocktwits.crawl(test_symbol, max_results=2)
            st.write(f"StockTwits: {len(st_n)} æ¡")
            
            # ApeWisdom
            ape = crawler.apewisdom.get_symbol_mentions(test_symbol)
            st.write(f"ApeWisdom: {'æ‰¾åˆ°' if ape else 'æœªåœ¨çƒ­æ¦œ'}")
            
            # Finnhub
            if crawler.finnhub.is_available:
                fh = crawler.finnhub.crawl(test_symbol, max_results=2)
                st.write(f"Finnhub: {len(fh)} æ¡")
            else:
                st.write("Finnhub: âš ï¸ æ—  key")
            
            # Polygon
            if crawler.polygon.is_available:
                pg = crawler.polygon.crawl(test_symbol, max_results=2)
                st.write(f"Polygon: {len(pg)} æ¡")
            else:
                st.write("Polygon: âš ï¸ æ—  key")


# å¯¼å‡º
def get_news_center_page():
    return render_news_center_page
