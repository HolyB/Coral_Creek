"""
XGBoost ä¿¡å·é¢„æµ‹æ¨¡å‹è®­ç»ƒ
Train XGBoost Signal Predictor

åŠŸèƒ½:
- ä»æ•°æ®åº“åŠ è½½å†å²ä¿¡å·æ•°æ®
- ç”ŸæˆæŠ€æœ¯ç‰¹å¾
- è®­ç»ƒ XGBoost åˆ†ç±»å™¨é¢„æµ‹ä¿¡å·ç›ˆåˆ©æ¦‚ç‡
- ä¿å­˜æ¨¡å‹åˆ°æœ¬åœ° / HuggingFace Hub

ç”¨æ³•:
    python train_xgb.py --market US --days 180 --upload
"""

import os
import sys
import argparse
import numpy as np
import pandas as pd
from datetime import date, timedelta
from pathlib import Path
from typing import Tuple, Dict, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ML åº“
try:
    import xgboost as xgb
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import (
        accuracy_score, precision_score, recall_score, f1_score,
        roc_auc_score, classification_report, confusion_matrix
    )
    ML_AVAILABLE = True
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
    print("   è¿è¡Œ: pip install xgboost scikit-learn")
    ML_AVAILABLE = False


class SignalDataset:
    """ä¿¡å·æ•°æ®é›†ç”Ÿæˆå™¨"""
    
    def __init__(self, market: str = 'US', holding_days: int = 5):
        self.market = market
        self.holding_days = holding_days
    
    def load_signals(self, days_back: int = 180) -> pd.DataFrame:
        """ä»æ•°æ®åº“åŠ è½½å†å²ä¿¡å·"""
        from db.database import get_connection
        
        conn = get_connection()
        
        end_date = date.today() - timedelta(days=self.holding_days)
        start_date = end_date - timedelta(days=days_back)
        
        query = """
            SELECT * FROM scan_results
            WHERE market = ? 
              AND scan_date >= ? 
              AND scan_date <= ?
            ORDER BY scan_date, symbol
        """
        
        df = pd.read_sql_query(query, conn, params=(
            self.market,
            start_date.strftime('%Y-%m-%d'),
            end_date.strftime('%Y-%m-%d')
        ))
        
        conn.close()
        print(f"ğŸ“Š åŠ è½½ {len(df)} æ¡ä¿¡å·è®°å½•")
        return df
    
    def calculate_labels(self, df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—æ ‡ç­¾ (Nå¤©åæ˜¯å¦ç›ˆåˆ©)"""
        from db.database import get_connection
        
        if df.empty:
            return df
        
        conn = get_connection()
        results = []
        
        for _, row in df.iterrows():
            symbol = row['symbol']
            signal_date = row['scan_date']
            entry_price = row.get('price', 0)
            
            if not entry_price or entry_price <= 0:
                continue
            
            # æŸ¥æ‰¾ N å¤©åçš„ä»·æ ¼
            exit_date = (pd.to_datetime(signal_date) + timedelta(days=self.holding_days)).strftime('%Y-%m-%d')
            
            cursor = conn.cursor()
            cursor.execute("""
                SELECT price FROM scan_results
                WHERE symbol = ? AND market = ? AND scan_date >= ?
                ORDER BY scan_date LIMIT 1
            """, (symbol, self.market, exit_date))
            
            exit_row = cursor.fetchone()
            
            if exit_row and exit_row['price']:
                exit_price = exit_row['price']
                return_pct = (exit_price - entry_price) / entry_price
                
                row_dict = row.to_dict()
                row_dict['exit_price'] = exit_price
                row_dict['return_pct'] = return_pct
                row_dict['is_win'] = 1 if return_pct > 0 else 0  # äºŒåˆ†ç±»æ ‡ç­¾
                results.append(row_dict)
        
        conn.close()
        
        result_df = pd.DataFrame(results)
        print(f"ğŸ“Š æœ‰æ•ˆæ ·æœ¬: {len(result_df)} (èƒœç‡: {result_df['is_win'].mean():.1%})")
        return result_df
    
    def create_features(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, list]:
        """åˆ›å»ºç‰¹å¾"""
        if df.empty:
            return pd.DataFrame(), []
        
        feature_cols = []
        
        # 1. BLUE ä¿¡å·ç‰¹å¾
        for col in ['blue_daily', 'blue_weekly', 'blue_monthly']:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
                feature_cols.append(col)
        
        # 2. ä¿¡å·ç»„åˆç‰¹å¾
        if 'blue_daily' in df.columns and 'blue_weekly' in df.columns:
            df['blue_daily_weekly_ratio'] = df['blue_daily'] / (df['blue_weekly'] + 1)
            df['blue_resonance'] = ((df['blue_daily'] >= 100) & (df['blue_weekly'] >= 100)).astype(int)
            feature_cols.extend(['blue_daily_weekly_ratio', 'blue_resonance'])
        
        # 3. é»‘é©¬/ç»åœ°ä¿¡å·
        for col in ['is_heima', 'is_juedi']:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)
                feature_cols.append(col)
        
        # 4. ä»·æ ¼ç‰¹å¾
        if 'price' in df.columns:
            df['log_price'] = np.log1p(df['price'])
            feature_cols.append('log_price')
        
        # 5. æ˜Ÿçº§è¯„åˆ†
        if 'star_rating' in df.columns:
            df['star_rating'] = pd.to_numeric(df['star_rating'], errors='coerce').fillna(0)
            feature_cols.append('star_rating')
        
        # 6. æ—¶é—´ç‰¹å¾
        df['scan_date'] = pd.to_datetime(df['scan_date'])
        df['day_of_week'] = df['scan_date'].dt.dayofweek
        df['month'] = df['scan_date'].dt.month
        feature_cols.extend(['day_of_week', 'month'])
        
        print(f"ğŸ“Š ç‰¹å¾æ•°é‡: {len(feature_cols)}")
        return df, feature_cols
    
    def prepare_dataset(self, days_back: int = 180) -> Tuple[np.ndarray, np.ndarray, list, pd.DataFrame]:
        """
        å‡†å¤‡å®Œæ•´æ•°æ®é›†
        
        Returns:
            X: ç‰¹å¾çŸ©é˜µ
            y: æ ‡ç­¾
            feature_names: ç‰¹å¾åç§°åˆ—è¡¨
            df: åŸå§‹æ•°æ®
        """
        # 1. åŠ è½½æ•°æ®
        df = self.load_signals(days_back)
        
        if df.empty:
            print("âŒ æ— æ•°æ®")
            return None, None, None, None
        
        # 2. è®¡ç®—æ ‡ç­¾
        df = self.calculate_labels(df)
        
        if df.empty or 'is_win' not in df.columns:
            print("âŒ æ— æ³•è®¡ç®—æ ‡ç­¾")
            return None, None, None, None
        
        # 3. åˆ›å»ºç‰¹å¾
        df, feature_cols = self.create_features(df)
        
        # 4. æå– X, y
        X = df[feature_cols].values
        y = df['is_win'].values
        
        # å¤„ç† NaN
        X = np.nan_to_num(X, nan=0.0)
        
        return X, y, feature_cols, df


class XGBSignalPredictor:
    """XGBoost ä¿¡å·é¢„æµ‹å™¨"""
    
    def __init__(self, **params):
        self.params = {
            'n_estimators': 200,
            'max_depth': 4,
            'learning_rate': 0.05,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'objective': 'binary:logistic',
            'eval_metric': 'auc',
            'scale_pos_weight': 1,  # ä¼šåœ¨è®­ç»ƒæ—¶åŠ¨æ€è®¡ç®—
            'random_state': 42,
            **params
        }
        self.model = None
        self.feature_names = None
        self.metrics = {}
    
    def train(self, X: np.ndarray, y: np.ndarray, 
              feature_names: list = None,
              test_size: float = 0.2) -> Dict:
        """
        è®­ç»ƒæ¨¡å‹
        
        Returns:
            è®­ç»ƒæŒ‡æ ‡
        """
        self.feature_names = feature_names or [f'f{i}' for i in range(X.shape[1])]
        
        # åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )
        
        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ...")
        print(f"   è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
        print(f"   æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
        print(f"   æ­£æ ·æœ¬æ¯”ä¾‹: {y_train.mean():.1%}")
        
        # å¤„ç†ä¸å¹³è¡¡æ•°æ®ï¼šè®¡ç®— scale_pos_weight
        neg_count = (y_train == 0).sum()
        pos_count = (y_train == 1).sum()
        scale_pos_weight = neg_count / pos_count if pos_count > 0 else 1
        self.params['scale_pos_weight'] = scale_pos_weight
        print(f"   ä¸å¹³è¡¡æƒé‡: {scale_pos_weight:.1f}")
        
        # è®­ç»ƒ
        self.model = xgb.XGBClassifier(**self.params)
        self.model.fit(
            X_train, y_train,
            eval_set=[(X_test, y_test)],
            verbose=False
        )
        
        # è¯„ä¼°
        y_pred = self.model.predict(X_test)
        y_prob = self.model.predict_proba(X_test)[:, 1]
        
        self.metrics = {
            'accuracy': accuracy_score(y_test, y_pred),
            'precision': precision_score(y_test, y_pred),
            'recall': recall_score(y_test, y_pred),
            'f1': f1_score(y_test, y_pred),
            'auc': roc_auc_score(y_test, y_prob),
            'train_samples': len(X_train),
            'test_samples': len(X_test),
            'positive_ratio': float(y_train.mean())
        }
        
        print(f"\nğŸ“ˆ æ¨¡å‹æ€§èƒ½:")
        print(f"   Accuracy:  {self.metrics['accuracy']:.3f}")
        print(f"   Precision: {self.metrics['precision']:.3f}")
        print(f"   Recall:    {self.metrics['recall']:.3f}")
        print(f"   F1 Score:  {self.metrics['f1']:.3f}")
        print(f"   AUC:       {self.metrics['auc']:.3f}")
        
        # ç‰¹å¾é‡è¦æ€§
        print(f"\nğŸ” ç‰¹å¾é‡è¦æ€§ (Top 10):")
        importance = dict(zip(self.feature_names, self.model.feature_importances_))
        sorted_imp = sorted(importance.items(), key=lambda x: x[1], reverse=True)
        for feat, imp in sorted_imp[:10]:
            print(f"   {feat}: {imp:.3f}")
        
        return self.metrics
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """é¢„æµ‹ç±»åˆ«"""
        if self.model is None:
            raise RuntimeError("æ¨¡å‹æœªè®­ç»ƒ")
        return self.model.predict(X)
    
    def predict_proba(self, X: np.ndarray) -> np.ndarray:
        """é¢„æµ‹æ¦‚ç‡"""
        if self.model is None:
            raise RuntimeError("æ¨¡å‹æœªè®­ç»ƒ")
        return self.model.predict_proba(X)[:, 1]
    
    def get_feature_importance(self) -> Dict[str, float]:
        """è·å–ç‰¹å¾é‡è¦æ€§"""
        if self.model is None or self.feature_names is None:
            return {}
        return dict(zip(self.feature_names, self.model.feature_importances_))


def train_and_save(market: str = 'US', 
                   days_back: int = 180,
                   holding_days: int = 5,
                   upload: bool = False) -> Optional[XGBSignalPredictor]:
    """
    å®Œæ•´è®­ç»ƒæµç¨‹
    
    Args:
        market: å¸‚åœº ('US' or 'CN')
        days_back: è®­ç»ƒæ•°æ®å¤©æ•°
        holding_days: æŒæœ‰å¤©æ•°
        upload: æ˜¯å¦ä¸Šä¼ åˆ° HuggingFace Hub
    
    Returns:
        è®­ç»ƒå¥½çš„æ¨¡å‹
    """
    if not ML_AVAILABLE:
        print("âŒ ML ä¾èµ–æœªå®‰è£…")
        return None
    
    print(f"=" * 50)
    print(f"ğŸ¯ XGBoost ä¿¡å·é¢„æµ‹æ¨¡å‹è®­ç»ƒ")
    print(f"   å¸‚åœº: {market}")
    print(f"   æ•°æ®: è¿‘ {days_back} å¤©")
    print(f"   æŒæœ‰æœŸ: {holding_days} å¤©")
    print(f"=" * 50)
    
    # 1. å‡†å¤‡æ•°æ®
    dataset = SignalDataset(market=market, holding_days=holding_days)
    X, y, feature_names, df = dataset.prepare_dataset(days_back)
    
    if X is None:
        print("âŒ æ•°æ®å‡†å¤‡å¤±è´¥")
        return None
    
    # 2. è®­ç»ƒæ¨¡å‹
    predictor = XGBSignalPredictor()
    metrics = predictor.train(X, y, feature_names)
    
    # 3. ä¿å­˜æ¨¡å‹
    from ml.model_registry import save_model
    
    model_name = f"xgb_signal_{market.lower()}"
    metadata = {
        'market': market,
        'days_back': days_back,
        'holding_days': holding_days,
        'feature_names': feature_names,
        **metrics
    }
    
    save_model(predictor.model, model_name, metadata, upload=upload)
    
    # åŒæ—¶ä¿å­˜ç‰¹å¾åç§°ï¼ˆæ¨ç†æ—¶éœ€è¦ï¼‰
    predictor_path = Path(__file__).parent / "saved_models" / model_name
    import json
    with open(predictor_path / "feature_names.json", 'w') as f:
        json.dump(feature_names, f)
    
    print(f"\nâœ… è®­ç»ƒå®Œæˆ!")
    return predictor


# === å‘½ä»¤è¡Œå…¥å£ ===
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='è®­ç»ƒ XGBoost ä¿¡å·é¢„æµ‹æ¨¡å‹')
    parser.add_argument('--market', type=str, default='US', choices=['US', 'CN'],
                       help='å¸‚åœº (US/CN)')
    parser.add_argument('--days', type=int, default=180,
                       help='è®­ç»ƒæ•°æ®å¤©æ•°')
    parser.add_argument('--holding', type=int, default=5,
                       help='æŒæœ‰å¤©æ•°')
    parser.add_argument('--upload', action='store_true',
                       help='ä¸Šä¼ åˆ° HuggingFace Hub')
    
    args = parser.parse_args()
    
    train_and_save(
        market=args.market,
        days_back=args.days,
        holding_days=args.holding,
        upload=args.upload
    )
