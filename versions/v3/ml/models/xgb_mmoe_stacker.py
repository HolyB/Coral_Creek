#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
XGBoost â†’ MMoE Stacking æ¨¡å‹
============================

æ¶æ„:
  åŸå§‹ç‰¹å¾ (110)
       â”‚
  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
  â”‚ XGBoost â”‚ (Stage 1: ç‰¹å¾äº¤äº’ + å¶å­ç¼–ç )
  â”‚ 5d pred â”‚
  â”‚ 20d predâ”‚
  â”‚ leaf idxâ”‚ â†’ one-hot â†’ é™ç»´
  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
       â”‚ æ‹¼æ¥: åŸå§‹ç‰¹å¾ + XGB è¾“å‡º (110 + K)
       â”‚
  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
  â”‚  MMoE   â”‚ (Stage 2: å¤šä»»åŠ¡å­¦ä¹ )
  â”‚ 6 tasks â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ä¼˜åŠ¿:
  - XGBoost æ•è·é«˜é˜¶éçº¿æ€§ç‰¹å¾äº¤äº’
  - MMoE åšå¤šä»»åŠ¡çš„è·¨å‘¨æœŸä¿¡æ¯ä¼ é€’
  - å¶å­ç¼–ç  = è‡ªåŠ¨ç‰¹å¾ç¦»æ•£åŒ– + äº¤å‰
"""

import numpy as np
import warnings
warnings.filterwarnings('ignore')

from typing import Dict, List, Optional
from pathlib import Path
import json
import joblib

TORCH_AVAILABLE = False
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    pass

from ml.models.mmoe import MMoEPredictor, TASK_DEFS


class XGBMMoEStacker:
    """XGBoost â†’ MMoE ä¸¤é˜¶æ®µ Stacking æ¨¡å‹"""

    def __init__(self,
                 # XGBoost å‚æ•°
                 xgb_max_depth: int = 4,
                 xgb_lr: float = 0.03,
                 xgb_n_estimators: int = 300,
                 xgb_leaf_dim: int = 16,  # å¶å­ç¼–ç é™ç»´ç»´åº¦
                 # MMoE å‚æ•°
                 num_experts: int = 4,
                 expert_hidden: int = 64,
                 expert_out: int = 32,
                 tower_hidden: int = 16,
                 dropout: float = 0.2,
                 mmoe_lr: float = 5e-4,
                 mmoe_epochs: int = 200,
                 mmoe_patience: int = 25,
                 mmoe_batch: int = 128):

        self.xgb_config = dict(
            max_depth=xgb_max_depth, lr=xgb_lr,
            n_estimators=xgb_n_estimators, leaf_dim=xgb_leaf_dim,
        )
        self.mmoe_config = dict(
            num_experts=num_experts, expert_hidden=expert_hidden,
            expert_out=expert_out, tower_hidden=tower_hidden,
            dropout=dropout, lr=mmoe_lr, epochs=mmoe_epochs,
            patience=mmoe_patience, batch_size=mmoe_batch,
        )

        self.xgb_5d = None
        self.xgb_20d = None
        self.leaf_pca = None  # PCA é™ç»´å¶å­ç¼–ç 
        self.mmoe = None
        self.feature_names: List[str] = []
        self.stacked_feature_names: List[str] = []

    def _train_xgb_stage(self, X, returns_dict, groups, val_ratio=0.2):
        """Stage 1: è®­ç»ƒ XGBoostï¼Œæå–å¶å­ç¼–ç """
        try:
            from xgboost import XGBRegressor
        except ImportError:
            raise ImportError("pip install xgboost")

        from sklearn.decomposition import PCA

        y_5d = np.nan_to_num(returns_dict.get('5d', np.zeros(len(X))), 0.0)
        y_20d = np.nan_to_num(returns_dict.get('20d', np.zeros(len(X))), 0.0)

        # æ—¶åºåˆ†å‰² (ç”¨ groups)
        ugroups = sorted(set(groups))
        split = int(len(ugroups) * (1 - val_ratio))
        train_g = set(ugroups[:split])
        tmask = np.array([g in train_g for g in groups])

        X_tr, X_va = X[tmask], X[~tmask]
        y5_tr, y5_va = y_5d[tmask], y_5d[~tmask]
        y20_tr, y20_va = y_20d[tmask], y_20d[~tmask]

        print(f"\nğŸ“ˆ Stage 1: XGBoost ç‰¹å¾æå–")
        print(f"   è®­ç»ƒ: {len(X_tr)}, éªŒè¯: {len(X_va)}")

        # 5d model
        self.xgb_5d = XGBRegressor(
            max_depth=self.xgb_config['max_depth'],
            learning_rate=self.xgb_config['lr'],
            n_estimators=self.xgb_config['n_estimators'],
            subsample=0.8, colsample_bytree=0.8,
            reg_alpha=0.1, reg_lambda=1.0,
            random_state=42, verbosity=0,
        )
        self.xgb_5d.fit(X_tr, y5_tr, eval_set=[(X_va, y5_va)],
                        verbose=False)

        pred_5d = self.xgb_5d.predict(X)
        from sklearn.metrics import mean_absolute_error
        mae_5d = mean_absolute_error(y5_va, self.xgb_5d.predict(X_va))
        print(f"   XGB 5d MAE: {mae_5d:.2f}%")

        # 20d model
        self.xgb_20d = XGBRegressor(
            max_depth=self.xgb_config['max_depth'] + 1,
            learning_rate=self.xgb_config['lr'],
            n_estimators=self.xgb_config['n_estimators'],
            subsample=0.8, colsample_bytree=0.8,
            reg_alpha=0.1, reg_lambda=1.0,
            random_state=42, verbosity=0,
        )
        self.xgb_20d.fit(X_tr, y20_tr, eval_set=[(X_va, y20_va)],
                         verbose=False)
        pred_20d = self.xgb_20d.predict(X)
        mae_20d = mean_absolute_error(y20_va, self.xgb_20d.predict(X_va))
        print(f"   XGB 20d MAE: {mae_20d:.2f}%")

        # å¶å­ç¼–ç 
        leaf_5d = self.xgb_5d.apply(X)   # (n, n_trees) æ¯æ£µæ ‘çš„å¶å­èŠ‚ç‚¹ ID
        leaf_20d = self.xgb_20d.apply(X)
        leaf_all = np.hstack([leaf_5d, leaf_20d]).astype(float)

        # PCA é™ç»´å¶å­ç¼–ç  (ä» 600â†’leaf_dim)
        leaf_dim = self.xgb_config['leaf_dim']
        self.leaf_pca = PCA(n_components=min(leaf_dim, leaf_all.shape[1]))
        leaf_reduced = self.leaf_pca.fit_transform(leaf_all)
        print(f"   å¶å­ç¼–ç : {leaf_all.shape[1]} â†’ PCA â†’ {leaf_reduced.shape[1]}")

        # æ‹¼æ¥: åŸå§‹ç‰¹å¾ + XGB é¢„æµ‹ + å¶å­ç¼–ç 
        xgb_features = np.column_stack([
            pred_5d.reshape(-1, 1),
            pred_20d.reshape(-1, 1),
            (pred_5d > 0).astype(float).reshape(-1, 1),  # XGB æ–¹å‘
            np.abs(pred_5d).reshape(-1, 1),               # XGB ä¿¡å¿ƒ
            leaf_reduced,
        ])

        n_xgb = xgb_features.shape[1]
        xgb_feat_names = (
            ['xgb_pred_5d', 'xgb_pred_20d', 'xgb_dir_5d', 'xgb_confidence']
            + [f'xgb_leaf_{i}' for i in range(leaf_reduced.shape[1])]
        )

        X_stacked = np.hstack([X, xgb_features])
        print(f"   å †å ç‰¹å¾: {X.shape[1]} + {n_xgb} = {X_stacked.shape[1]}")

        return X_stacked, xgb_feat_names, {'mae_5d': mae_5d, 'mae_20d': mae_20d}

    def _extract_xgb_features(self, X):
        """å¯¹æ–°æ•°æ®æå– XGB ç‰¹å¾"""
        pred_5d = self.xgb_5d.predict(X)
        pred_20d = self.xgb_20d.predict(X)

        leaf_5d = self.xgb_5d.apply(X).astype(float)
        leaf_20d = self.xgb_20d.apply(X).astype(float)
        leaf_all = np.hstack([leaf_5d, leaf_20d])
        leaf_reduced = self.leaf_pca.transform(leaf_all)

        xgb_features = np.column_stack([
            pred_5d.reshape(-1, 1),
            pred_20d.reshape(-1, 1),
            (pred_5d > 0).astype(float).reshape(-1, 1),
            np.abs(pred_5d).reshape(-1, 1),
            leaf_reduced,
        ])
        return np.hstack([X, xgb_features])

    def train(self,
              X: np.ndarray,
              returns_dict: Dict[str, np.ndarray],
              feature_names: List[str],
              groups: np.ndarray,
              drawdowns_dict: Optional[Dict[str, np.ndarray]] = None,
              val_ratio: float = 0.2) -> Dict:
        """ä¸¤é˜¶æ®µè®­ç»ƒ"""
        self.feature_names = feature_names

        print(f"\n{'='*60}")
        print(f"ğŸ—ï¸  XGBoost â†’ MMoE Stacking")
        print(f"   æ ·æœ¬: {X.shape[0]}, åŸå§‹ç‰¹å¾: {X.shape[1]}")
        print(f"{'='*60}")

        # Stage 1: XGBoost
        X_stacked, xgb_feat_names, xgb_metrics = self._train_xgb_stage(
            X, returns_dict, groups, val_ratio)
        self.stacked_feature_names = feature_names + xgb_feat_names

        # Stage 2: MMoE
        print(f"\nğŸ§  Stage 2: MMoE å¤šä»»åŠ¡å­¦ä¹ ")
        self.mmoe = MMoEPredictor(**self.mmoe_config)
        mmoe_results = self.mmoe.train(
            X_stacked, returns_dict, self.stacked_feature_names,
            groups, drawdowns_dict, val_ratio)

        results = {
            'stage1_xgb': xgb_metrics,
            'stage2_mmoe': mmoe_results,
            'total_features': X_stacked.shape[1],
            'original_features': X.shape[1],
            'xgb_added_features': X_stacked.shape[1] - X.shape[1],
        }

        return results

    def predict(self, X: np.ndarray) -> Dict[str, np.ndarray]:
        """ä¸¤é˜¶æ®µé¢„æµ‹"""
        X_stacked = self._extract_xgb_features(X)
        return self.mmoe.predict(X_stacked)

    def save(self, path: str):
        p = Path(path); p.mkdir(parents=True, exist_ok=True)
        joblib.dump(self.xgb_5d, p / 'xgb_5d.joblib')
        joblib.dump(self.xgb_20d, p / 'xgb_20d.joblib')
        joblib.dump(self.leaf_pca, p / 'leaf_pca.joblib')
        self.mmoe.save(str(p / 'mmoe'))
        meta = {
            'feature_names': self.feature_names,
            'stacked_feature_names': self.stacked_feature_names,
            'xgb_config': self.xgb_config,
            'mmoe_config': self.mmoe_config,
        }
        with open(p / 'stacker_meta.json', 'w') as f:
            json.dump(meta, f, indent=2)
        print(f"âœ… Stacking æ¨¡å‹å·²ä¿å­˜: {p}")

    def load(self, path: str):
        p = Path(path)
        with open(p / 'stacker_meta.json') as f:
            meta = json.load(f)
        self.feature_names = meta['feature_names']
        self.stacked_feature_names = meta['stacked_feature_names']
        self.xgb_config = meta['xgb_config']
        self.mmoe_config = meta['mmoe_config']
        self.xgb_5d = joblib.load(p / 'xgb_5d.joblib')
        self.xgb_20d = joblib.load(p / 'xgb_20d.joblib')
        self.leaf_pca = joblib.load(p / 'leaf_pca.joblib')
        self.mmoe = MMoEPredictor(**self.mmoe_config)
        self.mmoe.load(str(p / 'mmoe'))
        print(f"âœ… Stacking æ¨¡å‹å·²åŠ è½½: {p}")
