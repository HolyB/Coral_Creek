"""
ç®€åŒ–ç‰ˆ ML è®­ç»ƒ
ä½¿ç”¨æ•°æ®åº“å·²æœ‰çš„ scan_results æ•°æ®è®­ç»ƒ
ä¸ä¾èµ–å¤–éƒ¨ API
"""

import numpy as np
import pandas as pd
from datetime import date, timedelta, datetime
from pathlib import Path
import sys

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def train_simple(market: str = 'US', days_back: int = 60):
    """
    ç®€åŒ–ç‰ˆè®­ç»ƒ - åªä½¿ç”¨ scan_results ä¸­çš„æ•°æ®
    """
    from db.database import get_connection
    
    print(f"\n{'='*60}")
    print("ğŸš€ ç®€åŒ–ç‰ˆ ML è®­ç»ƒ (æ— å¤–éƒ¨ API)")
    print(f"   å¸‚åœº: {market}")
    print(f"   å¤©æ•°: {days_back}")
    print(f"{'='*60}")
    
    conn = get_connection()
    
    # è·å–æ—¥æœŸèŒƒå›´
    cursor = conn.cursor()
    cursor.execute("SELECT MAX(scan_date) FROM scan_results WHERE market = ?", (market,))
    max_date = cursor.fetchone()[0]
    
    if not max_date:
        print("âŒ æ— æ•°æ®")
        return None
    
    end_date = datetime.strptime(max_date, '%Y-%m-%d').date() - timedelta(days=5)
    start_date = end_date - timedelta(days=days_back)
    
    print(f"   æ—¥æœŸèŒƒå›´: {start_date} ~ {end_date}")
    
    # è·å–æ‰€æœ‰ä¿¡å·
    query = """
        SELECT symbol, scan_date, price, 
               COALESCE(blue_daily, 0) as blue_daily,
               COALESCE(blue_weekly, 0) as blue_weekly,
               COALESCE(blue_monthly, 0) as blue_monthly,
               COALESCE(is_heima, 0) as is_heima,
               COALESCE(is_juedi, 0) as is_juedi,
               COALESCE(volatility, 0) as volatility,
               COALESCE(adx, 0) as adx
        FROM scan_results
        WHERE market = ? AND scan_date >= ? AND scan_date <= ?
          AND price > 0
        ORDER BY symbol, scan_date
    """
    
    df = pd.read_sql_query(query, conn, params=(
        market, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')
    ))
    
    print(f"   åŸå§‹è®°å½•: {len(df)}")
    
    if len(df) < 100:
        print("âŒ æ•°æ®ä¸è¶³")
        conn.close()
        return None
    
    # è®¡ç®—æ ‡ç­¾ï¼š5å¤©åçš„æ”¶ç›Š
    # å¯¹äºæ¯ä¸ªä¿¡å·ï¼Œæ‰¾åŒä¸€è‚¡ç¥¨5å¤©åçš„ä»·æ ¼
    results = []
    
    for symbol in df['symbol'].unique():
        symbol_df = df[df['symbol'] == symbol].sort_values('scan_date')
        
        if len(symbol_df) < 2:
            continue
        
        for i in range(len(symbol_df) - 1):
            row = symbol_df.iloc[i]
            entry_price = row['price']
            entry_date = row['scan_date']
            
            # æ‰¾5å¤©åçš„ä»·æ ¼ (å¯èƒ½ä¸ç²¾ç¡®ï¼Œä½†ç”¨äºæ¼”ç¤º)
            future_df = symbol_df[symbol_df['scan_date'] > entry_date].head(5)
            
            if len(future_df) > 0:
                exit_price = future_df.iloc[-1]['price']
                return_5d = (exit_price - entry_price) / entry_price * 100
                
                results.append({
                    'symbol': symbol,
                    'scan_date': entry_date,
                    'price': entry_price,
                    'blue_daily': row['blue_daily'],
                    'blue_weekly': row['blue_weekly'],
                    'blue_monthly': row['blue_monthly'],
                    'is_heima': row['is_heima'],
                    'is_juedi': row['is_juedi'],
                    'volatility': row['volatility'],
                    'adx': row['adx'],
                    'return_5d': return_5d,
                    'is_win': 1 if return_5d > 0 else 0
                })
    
    conn.close()
    
    if len(results) < 50:
        print("âŒ æœ‰æ•ˆæ ·æœ¬ä¸è¶³")
        return None
    
    result_df = pd.DataFrame(results)
    print(f"   æœ‰æ•ˆæ ·æœ¬: {len(result_df)}")
    print(f"   èƒœç‡: {result_df['is_win'].mean():.1%}")
    print(f"   å¹³å‡æ”¶ç›Š: {result_df['return_5d'].mean():.2f}%")
    
    # åˆ›å»ºç‰¹å¾
    feature_cols = []
    
    # BLUE ç‰¹å¾
    result_df['blue_daily'] = pd.to_numeric(result_df['blue_daily'], errors='coerce').fillna(0)
    result_df['blue_weekly'] = pd.to_numeric(result_df['blue_weekly'], errors='coerce').fillna(0)
    result_df['blue_monthly'] = pd.to_numeric(result_df['blue_monthly'], errors='coerce').fillna(0)
    feature_cols.extend(['blue_daily', 'blue_weekly', 'blue_monthly'])
    
    # BLUE è¡ç”Ÿç‰¹å¾
    result_df['blue_dw_ratio'] = result_df['blue_daily'] / (result_df['blue_weekly'] + 1)
    result_df['blue_dw_resonance'] = ((result_df['blue_daily'] >= 100) & (result_df['blue_weekly'] >= 100)).astype(int)
    result_df['blue_dwm_resonance'] = ((result_df['blue_daily'] >= 100) & (result_df['blue_weekly'] >= 100) & (result_df['blue_monthly'] >= 100)).astype(int)
    feature_cols.extend(['blue_dw_ratio', 'blue_dw_resonance', 'blue_dwm_resonance'])
    
    # ä¿¡å·ç‰¹å¾
    result_df['is_heima'] = pd.to_numeric(result_df['is_heima'], errors='coerce').fillna(0).astype(int)
    result_df['is_juedi'] = pd.to_numeric(result_df['is_juedi'], errors='coerce').fillna(0).astype(int)
    feature_cols.extend(['is_heima', 'is_juedi'])
    
    # å…¶ä»–ç‰¹å¾
    result_df['log_price'] = np.log1p(result_df['price'])
    result_df['volatility'] = pd.to_numeric(result_df['volatility'], errors='coerce').fillna(0)
    result_df['adx'] = pd.to_numeric(result_df['adx'], errors='coerce').fillna(0)
    feature_cols.extend(['log_price', 'volatility', 'adx'])
    
    # ä¿¡å·å¼ºåº¦
    result_df['signal_strength'] = (
        (result_df['blue_daily'] >= 100).astype(int) +
        (result_df['blue_weekly'] >= 100).astype(int) +
        (result_df['blue_monthly'] >= 100).astype(int) +
        result_df['is_heima'] * 2
    )
    feature_cols.append('signal_strength')
    
    # æ—¶é—´ç‰¹å¾
    result_df['scan_date'] = pd.to_datetime(result_df['scan_date'])
    result_df['day_of_week'] = result_df['scan_date'].dt.dayofweek
    result_df['month'] = result_df['scan_date'].dt.month
    feature_cols.extend(['day_of_week', 'month'])
    
    print(f"   ç‰¹å¾æ•°: {len(feature_cols)}")
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    X = result_df[feature_cols].values
    X = np.nan_to_num(X, nan=0.0)
    
    y_class = result_df['is_win'].values
    y_reg = result_df['return_5d'].values
    
    # è®­ç»ƒåˆ†ç±»æ¨¡å‹
    print(f"\n{'='*60}")
    print("ğŸ“Š è®­ç»ƒåˆ†ç±»æ¨¡å‹ (é¢„æµ‹æ¶¨è·Œ)")
    
    try:
        import xgboost as xgb
        from sklearn.model_selection import train_test_split
        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_class, test_size=0.2, random_state=42, stratify=y_class
        )
        
        # å¤„ç†ä¸å¹³è¡¡
        neg_count = (y_train == 0).sum()
        pos_count = (y_train == 1).sum()
        scale_pos_weight = neg_count / pos_count if pos_count > 0 else 1
        
        print(f"   è®­ç»ƒé›†: {len(X_train)}, æµ‹è¯•é›†: {len(X_test)}")
        print(f"   æ­£æ ·æœ¬æ¯”ä¾‹: {y_train.mean():.1%}")
        print(f"   ä¸å¹³è¡¡æƒé‡: {scale_pos_weight:.1f}")
        
        model_class = xgb.XGBClassifier(
            n_estimators=200,
            max_depth=4,
            learning_rate=0.05,
            scale_pos_weight=scale_pos_weight,
            random_state=42
        )
        model_class.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)
        
        y_pred = model_class.predict(X_test)
        y_prob = model_class.predict_proba(X_test)[:, 1]
        
        print(f"\nğŸ“ˆ åˆ†ç±»æ¨¡å‹æ€§èƒ½:")
        print(f"   Accuracy:  {accuracy_score(y_test, y_pred):.3f}")
        print(f"   Precision: {precision_score(y_test, y_pred):.3f}")
        print(f"   Recall:    {recall_score(y_test, y_pred):.3f}")
        print(f"   F1:        {f1_score(y_test, y_pred):.3f}")
        print(f"   AUC:       {roc_auc_score(y_test, y_prob):.3f}")
        
        # ç‰¹å¾é‡è¦æ€§
        print(f"\nğŸ” ç‰¹å¾é‡è¦æ€§:")
        importance = dict(zip(feature_cols, model_class.feature_importances_))
        for feat, imp in sorted(importance.items(), key=lambda x: x[1], reverse=True)[:10]:
            print(f"   {feat}: {imp:.3f}")
        
        # è®­ç»ƒå›å½’æ¨¡å‹
        print(f"\n{'='*60}")
        print("ğŸ“Š è®­ç»ƒå›å½’æ¨¡å‹ (é¢„æµ‹æ”¶ç›Šç‡)")
        
        X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(
            X, y_reg, test_size=0.2, random_state=42
        )
        
        model_reg = xgb.XGBRegressor(
            n_estimators=200,
            max_depth=4,
            learning_rate=0.05,
            random_state=42
        )
        model_reg.fit(X_train_r, y_train_r, eval_set=[(X_test_r, y_test_r)], verbose=False)
        
        y_pred_r = model_reg.predict(X_test_r)
        
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        
        rmse = np.sqrt(mean_squared_error(y_test_r, y_pred_r))
        mae = mean_absolute_error(y_test_r, y_pred_r)
        r2 = r2_score(y_test_r, y_pred_r)
        direction_acc = ((y_pred_r > 0) == (y_test_r > 0)).mean()
        
        print(f"\nğŸ“ˆ å›å½’æ¨¡å‹æ€§èƒ½:")
        print(f"   RMSE:      {rmse:.2f}%")
        print(f"   MAE:       {mae:.2f}%")
        print(f"   RÂ²:        {r2:.3f}")
        print(f"   æ–¹å‘å‡†ç¡®ç‡: {direction_acc:.1%}")
        
        # ä¿å­˜æ¨¡å‹
        import joblib
        
        model_dir = Path(__file__).parent / "saved_models" / f"simple_{market.lower()}"
        model_dir.mkdir(parents=True, exist_ok=True)
        
        joblib.dump(model_class, model_dir / "classifier.joblib")
        joblib.dump(model_reg, model_dir / "regressor.joblib")
        
        import json
        with open(model_dir / "feature_names.json", 'w') as f:
            json.dump(feature_cols, f)
        
        with open(model_dir / "metadata.json", 'w') as f:
            json.dump({
                'market': market,
                'train_samples': len(X_train),
                'test_samples': len(X_test),
                'features': feature_cols,
                'classifier_auc': float(roc_auc_score(y_test, y_prob)),
                'regressor_r2': float(r2),
                'direction_accuracy': float(direction_acc)
            }, f, indent=2)
        
        print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_dir}")
        
        return {
            'status': 'success',
            'samples': len(result_df),
            'classifier_auc': roc_auc_score(y_test, y_prob),
            'regressor_r2': r2,
            'direction_accuracy': direction_acc
        }
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser()
    parser.add_argument('--market', default='US')
    parser.add_argument('--days', type=int, default=60)
    
    args = parser.parse_args()
    
    result = train_simple(args.market, args.days)
    print(f"\nç»“æœ: {result}")
