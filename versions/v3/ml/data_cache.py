"""
æ•°æ®ç¼“å­˜æ¨¡å— (Data Caching Layer)
==================================
è´Ÿè´£å°†è‚¡ç¥¨å†å²æ•°æ® (OHLCV) ä» Polygon/Tushare æ‹‰å–å¹¶ç¼“å­˜åˆ°æœ¬åœ° Parquet æ–‡ä»¶ã€‚
è¿™èƒ½æå¤§åŠ é€Ÿ Backfill å’Œ ML è®­ç»ƒï¼Œé¿å…é‡å¤ API è¯·æ±‚å’Œ SQLite é”ç«äº‰ã€‚

ä¾èµ–:
    - pandas
    - polygon-api-client
    - pyarrow (for parquet)

ç”¨æ³•:
    from ml.data_cache import DataCache
    cache = DataCache()
    
    # è·å–æ•°æ® (ä¼˜å…ˆè¯»ç¼“å­˜ï¼Œæ— ç¼“å­˜åˆ™ä¸‹è½½å¹¶ä¿å­˜)
    df = cache.get_stock_history("AAPL", market="US")
    
    # æ‰¹é‡é¢„çƒ­ç¼“å­˜
    cache.warmup_cache(["AAPL", "TSLA", "NVDA"])
"""

import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Optional

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)
    
try:
    from polygon import RESTClient
except ImportError:
    RESTClient = None

class DataCache:
    def __init__(self, cache_dir: str = None):
        if cache_dir is None:
            # é»˜è®¤å­˜æ”¾åœ¨ versions/v3/data/parquet
            self.base_dir = Path(parent_dir) / "data" / "parquet"
        else:
            self.base_dir = Path(cache_dir)
            
        self.us_dir = self.base_dir / "us"
        self.cn_dir = self.base_dir / "cn"
        
        # ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨
        self.us_dir.mkdir(parents=True, exist_ok=True)
        self.cn_dir.mkdir(parents=True, exist_ok=True)
        
        self.api_key = os.environ.get('POLYGON_API_KEY')
        self._client = None
        
    @property
    def client(self):
        if self._client is None and self.api_key:
            if RESTClient:
                self._client = RESTClient(self.api_key)
        return self._client

    def get_file_path(self, symbol: str, market: str = "US") -> Path:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        symbol = symbol.replace("/", "_").upper() # å¤„ç†ç‰¹æ®Šå­—ç¬¦
        if market == "US":
            return self.us_dir / f"{symbol}.parquet"
        else:
            return self.cn_dir / f"{symbol}.parquet"

    def load_from_cache(self, symbol: str, market: str = "US", max_age_days: int = 1) -> Optional[pd.DataFrame]:
        """ä»ç¼“å­˜è¯»å–ï¼Œå¦‚æœå¤ªæ—§åˆ™è¿”å› None"""
        path = self.get_file_path(symbol, market)
        if not path.exists():
            return None
            
        # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´
        mtime = datetime.fromtimestamp(path.stat().st_mtime)
        age = datetime.now() - mtime
        
        # å¦‚æœæ˜¯ç›˜ä¸­å®æ—¶ä»»åŠ¡ï¼Œå¯èƒ½éœ€è¦æ›´çŸ­çš„è¿‡æœŸæ—¶é—´
        # ä½†å¯¹äº Backfill/MLï¼Œé€šå¸¸ä¸€å¤©ä¸€æ›´ç”šè‡³ä¸€å‘¨ä¸€æ›´éƒ½å¤Ÿäº†
        if age.days > max_age_days:
            pass # è¿™é‡Œå¯ä»¥åŠ é€»è¾‘ï¼šå¦‚æœéœ€è¦æœ€æ–°æ•°æ®ï¼Œåˆ™è§†ä¸ºè¿‡æœŸå¾…æ›´æ–°
            
        try:
            return pd.read_parquet(path)
        except getattr(Exception, 'None', Exception): # Capture all, prevent crash from corrupted file
            return None

    def fetch_from_polygon(self, symbol: str, days: int = 365*5) -> Optional[pd.DataFrame]:
        """ä» Polygon æ‹‰å–æ•°æ®"""
        if not self.client:
            print("âŒ Polygon Client æœªåˆå§‹åŒ– (Missing API Key?)")
            return None
            
        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=days)
        
        try:
            # ä½¿ç”¨ get_aggs (v2)
            aggs = []
            for a in self.client.list_aggs(
                symbol, 1, "day", 
                start_date.strftime("%Y-%m-%d"), 
                end_date.strftime("%Y-%m-%d"), 
                limit=50000
            ):
                aggs.append(a)
                
            if not aggs:
                return None
                
            records = []
            for a in aggs:
                if a.timestamp is None: continue
                dt = datetime.fromtimestamp(a.timestamp / 1000)
                
                # Safe float conversion
                def _sf(val):
                    try:
                        return float(val) if val is not None else 0.0
                    except:
                        return 0.0
                
                records.append({
                    'date': dt,
                    'open': _sf(a.open),
                    'high': _sf(a.high),
                    'low': _sf(a.low),
                    'close': _sf(a.close),
                    'volume': _sf(a.volume),
                    'vwap': _sf(a.vwap) if hasattr(a, 'vwap') else _sf(a.close)
                })
                
            df = pd.DataFrame(records)
            df['symbol'] = symbol
            # ç¡®ä¿æŒ‰æ—¶é—´æ’åº
            df = df.sort_values('date').reset_index(drop=True)
            return df
            
        except Exception as e:
            print(f"âš ï¸ Polygon Error for {symbol}: {e}")
            return None

    def save_to_cache(self, df: pd.DataFrame, symbol: str, market: str = "US"):
        """ä¿å­˜åˆ° Parquet"""
        if df is None or df.empty:
            return
        
        path = self.get_file_path(symbol, market)
        try:
            # ä½¿ç”¨ pyarrow å¼•æ“ï¼Œå‹ç¼©ä»¥èŠ‚çœç©ºé—´
            df.to_parquet(path, engine='pyarrow', compression='snappy')
        except Exception as e:
            print(f"âŒ Save Parquet Failed {symbol}: {e}")

    def get_stock_history(self, symbol: str, market: str = "US", days: int = 365*5, force_refresh: bool = False) -> Optional[pd.DataFrame]:
        """
        è·å–è‚¡ç¥¨å†å²æ•°æ® (ä¸»å…¥å£)
        1. å°è¯•è¯»ç¼“å­˜
        2. ç¼“å­˜ä¸å­˜åœ¨æˆ–è¿‡æœŸ -> ä¸‹è½½
        3. ä¿å­˜å¹¶è¿”å›
        """
        if not force_refresh:
            df = self.load_from_cache(symbol, market, max_age_days=1)
            if df is not None:
                return df
                
        # éœ€è¦ä¸‹è½½
        if market == "US":
            df = self.fetch_from_polygon(symbol, days)
        else:
            # CN é€»è¾‘æš‚ç•™ç©ºæˆ–æ¥ Tushare
            return None
            
        if df is not None:
            self.save_to_cache(df, symbol, market)
            
        return df

    def warmup_cache_batch(self, symbols: List[str], market: str = "US", max_workers: int = 10):
        """æ‰¹é‡é¢„çƒ­ç¼“å­˜ (å¤šçº¿ç¨‹)"""
        print(f"ğŸ”¥ Warming up cache for {len(symbols)} symbols ({market})...")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {
                executor.submit(self.get_stock_history, sym, market, 365*5, False): sym
                for sym in symbols
            }
            
            completed = 0
            for future in as_completed(futures):
                sym = futures[future]
                try:
                    res = future.result()
                    if res is not None:
                        completed += 1
                except Exception as e:
                    print(f"Error {sym}: {e}")
                    
                # ç®€å•çš„è¿›åº¦æ¡
                if completed % 100 == 0:
                    print(f"   Progress: {completed}/{len(symbols)}")
                    
        print(f"âœ… Cache warmup finished. {completed}/{len(symbols)} synced.")

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    cache = DataCache()
    df = cache.get_stock_history("AAPL", market="US")
    if df is not None:
        print(f"Successfully loaded AAPL: {len(df)} rows")
        print(df.tail())
    else:
        print("Failed to load AAPL")
