#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Tushareè¿æ¥è¯Šæ–­å’Œä¿®å¤å·¥å…·
ç”¨äºè§£å†³APIè¿æ¥è¶…æ—¶å’Œç½‘ç»œé—®é¢˜
"""

import tushare as ts
import requests
import time
import socket
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter
import logging
import pandas as pd # Added missing import for pandas

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Tushareé…ç½®
TUSHARE_TOKEN = 'gx03013e909f633ecb66722df66b360f070426613316ebf06ecd3482'

class TushareConnectionFix:
    """Tushareè¿æ¥ä¿®å¤å™¨"""
    
    def __init__(self, token=TUSHARE_TOKEN):
        self.token = token
        self.base_urls = [
            'http://api.waditu.com/dataapi',
            'https://api.waditu.com/dataapi',  # å°è¯•HTTPS
        ]
        self.backup_servers = [
            '103.26.0.2',
            '103.26.0.3', 
            '103.26.0.4',
            '103.26.0.5'
        ]
    
    def test_network_connectivity(self):
        """æµ‹è¯•ç½‘ç»œè¿é€šæ€§"""
        logger.info("ğŸ” å¼€å§‹ç½‘ç»œè¿é€šæ€§æµ‹è¯•...")
        
        # æµ‹è¯•DNSè§£æ
        try:
            socket.gethostbyname('api.waditu.com')
            logger.info("âœ… DNSè§£ææ­£å¸¸")
        except Exception as e:
            logger.error(f"âŒ DNSè§£æå¤±è´¥: {e}")
            return False
        
        # æµ‹è¯•ç«¯å£è¿é€šæ€§
        for ip in self.backup_servers:
            try:
                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                sock.settimeout(5)
                result = sock.connect_ex((ip, 80))
                sock.close()
                if result == 0:
                    logger.info(f"âœ… ç«¯å£80è¿é€š - IP: {ip}")
                else:
                    logger.warning(f"âš ï¸ ç«¯å£80ä¸é€š - IP: {ip}")
            except Exception as e:
                logger.error(f"âŒ è¿æ¥æµ‹è¯•å¤±è´¥ - IP: {ip}, é”™è¯¯: {e}")
        
        return True
    
    def create_robust_session(self, timeout=60):
        """åˆ›å»ºå¥å£®çš„HTTPä¼šè¯"""
        session = requests.Session()
        
        # è®¾ç½®é‡è¯•ç­–ç•¥
        retry_strategy = Retry(
            total=5,
            status_forcelist=[429, 500, 502, 503, 504],
            method_whitelist=["HEAD", "GET", "OPTIONS", "POST"],
            backoff_factor=2,
            raise_on_status=False
        )
        
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        # è®¾ç½®æ›´é•¿çš„è¶…æ—¶æ—¶é—´
        session.timeout = timeout
        
        # è®¾ç½®User-Agent
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        return session
    
    def test_api_endpoints(self):
        """æµ‹è¯•APIç«¯ç‚¹"""
        logger.info("ğŸ” æµ‹è¯•APIç«¯ç‚¹...")
        session = self.create_robust_session()
        
        for url in self.base_urls:
            try:
                logger.info(f"æµ‹è¯•ç«¯ç‚¹: {url}")
                
                # æ„é€ æµ‹è¯•è¯·æ±‚
                test_params = {
                    'api_name': 'stock_basic',
                    'token': self.token,
                    'params': {'list_status': 'L', 'limit': 10},
                    'fields': 'ts_code,symbol,name'
                }
                
                response = session.post(f"{url}/stock_basic", 
                                      json=test_params, 
                                      timeout=60)
                
                if response.status_code == 200:
                    logger.info(f"âœ… APIç«¯ç‚¹å¯ç”¨: {url}")
                    return url
                else:
                    logger.warning(f"âš ï¸ APIç«¯ç‚¹è¿”å›é”™è¯¯çŠ¶æ€: {url} - {response.status_code}")
                    
            except Exception as e:
                logger.error(f"âŒ APIç«¯ç‚¹æµ‹è¯•å¤±è´¥: {url} - {e}")
        
        return None
    
    def patch_tushare_timeout(self, timeout=120):
        """ä¿®è¡¥Tushareçš„è¶…æ—¶è®¾ç½®"""
        logger.info(f"ğŸ”§ ä¿®è¡¥Tushareè¶…æ—¶è®¾ç½®ä¸º {timeout} ç§’...")
        
        try:
            # è®¾ç½®token
            ts.set_token(self.token)
            
            # åˆ›å»ºå¸¦æ›´é•¿è¶…æ—¶çš„APIå®ä¾‹
            pro = ts.pro_api(token=self.token, timeout=timeout)
            
            logger.info("âœ… Tushare APIå®ä¾‹åˆ›å»ºæˆåŠŸ")
            return pro
            
        except Exception as e:
            logger.error(f"âŒ Tushare APIåˆ›å»ºå¤±è´¥: {e}")
            return None
    
    def test_stock_basic_api(self, pro_api):
        """æµ‹è¯•è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯"""
        logger.info("ğŸ” æµ‹è¯•è‚¡ç¥¨åŸºç¡€ä¿¡æ¯API...")
        
        try:
            # åˆ†æ‰¹è·å–ï¼Œé¿å…è¶…æ—¶
            stock_list = pro_api.stock_basic(
                exchange='',
                list_status='L',
                limit=50,  # é™åˆ¶æ•°é‡
                fields='ts_code,symbol,name,area,industry,list_date'
            )
            
            if not stock_list.empty:
                logger.info(f"âœ… æˆåŠŸè·å– {len(stock_list)} åªè‚¡ç¥¨ä¿¡æ¯")
                logger.info(f"ç¤ºä¾‹: {stock_list.head(3).to_string()}")
                return True
            else:
                logger.warning("âš ï¸ è·å–åˆ°ç©ºçš„è‚¡ç¥¨åˆ—è¡¨")
                return False
                
        except Exception as e:
            logger.error(f"âŒ è‚¡ç¥¨åŸºç¡€ä¿¡æ¯APIæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def apply_connection_fix(self):
        """åº”ç”¨è¿æ¥ä¿®å¤"""
        logger.info("ğŸš€ å¼€å§‹Tushareè¿æ¥ä¿®å¤...")
        
        # 1. æµ‹è¯•ç½‘ç»œ
        if not self.test_network_connectivity():
            logger.error("âŒ ç½‘ç»œè¿é€šæ€§æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®")
            return None
        
        # 2. æµ‹è¯•APIç«¯ç‚¹
        working_endpoint = self.test_api_endpoints()
        if not working_endpoint:
            logger.error("âŒ æ‰€æœ‰APIç«¯ç‚¹éƒ½æ— æ³•è®¿é—®")
            return None
        
        # 3. åˆ›å»ºä¿®å¤åçš„APIå®ä¾‹
        pro_api = self.patch_tushare_timeout(timeout=120)
        if not pro_api:
            return None
        
        # 4. æµ‹è¯•APIåŠŸèƒ½
        if self.test_stock_basic_api(pro_api):
            logger.info("ğŸ‰ Tushareè¿æ¥ä¿®å¤æˆåŠŸï¼")
            return pro_api
        else:
            logger.error("âŒ APIåŠŸèƒ½æµ‹è¯•å¤±è´¥")
            return None
    
    def get_stocks_with_retry(self, pro_api, batch_size=100, max_retries=3):
        """å¸¦é‡è¯•æœºåˆ¶çš„è‚¡ç¥¨åˆ—è¡¨è·å–"""
        logger.info("ğŸ“ˆ å¼€å§‹è·å–å®Œæ•´è‚¡ç¥¨åˆ—è¡¨...")
        
        all_stocks = []
        offset = 0
        
        while True:
            for retry in range(max_retries):
                try:
                    logger.info(f"è·å–æ‰¹æ¬¡ {offset//batch_size + 1}ï¼Œèµ·å§‹ä½ç½®: {offset}")
                    
                    batch_stocks = pro_api.stock_basic(
                        exchange='',
                        list_status='L',
                        offset=offset,
                        limit=batch_size,
                        fields='ts_code,symbol,name,area,industry,list_date,market'
                    )
                    
                    if batch_stocks.empty:
                        logger.info("âœ… æ‰€æœ‰è‚¡ç¥¨æ•°æ®è·å–å®Œæˆ")
                        return pd.concat(all_stocks, ignore_index=True) if all_stocks else pd.DataFrame()
                    
                    all_stocks.append(batch_stocks)
                    offset += batch_size
                    
                    logger.info(f"âœ… æˆåŠŸè·å– {len(batch_stocks)} åªè‚¡ç¥¨ï¼Œç´¯è®¡: {sum(len(df) for df in all_stocks)}")
                    
                    # é¿å…APIé¢‘ç‡é™åˆ¶
                    time.sleep(0.5)
                    break
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ æ‰¹æ¬¡è·å–å¤±è´¥ (é‡è¯• {retry+1}/{max_retries}): {e}")
                    if retry < max_retries - 1:
                        time.sleep(2 ** retry)  # æŒ‡æ•°é€€é¿
                    else:
                        logger.error(f"âŒ æ‰¹æ¬¡è·å–æœ€ç»ˆå¤±è´¥ï¼Œè·³è¿‡ä½ç½® {offset}")
                        offset += batch_size
                        break
        
        return pd.concat(all_stocks, ignore_index=True) if all_stocks else pd.DataFrame()

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ”§ Tushareè¿æ¥è¯Šæ–­å’Œä¿®å¤å·¥å…·")
    print("=" * 60)
    
    # åˆ›å»ºä¿®å¤å™¨
    fixer = TushareConnectionFix()
    
    # åº”ç”¨ä¿®å¤
    pro_api = fixer.apply_connection_fix()
    
    if pro_api:
        print("\n" + "=" * 60)
        print("ğŸ“Š è·å–å®Œæ•´è‚¡ç¥¨åˆ—è¡¨ç¤ºä¾‹")
        print("=" * 60)
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨
        stocks = fixer.get_stocks_with_retry(pro_api, batch_size=200)
        
        if not stocks.empty:
            print(f"âœ… æ€»å…±è·å– {len(stocks)} åªè‚¡ç¥¨")
            print("\nå‰10åªè‚¡ç¥¨ç¤ºä¾‹:")
            print(stocks.head(10).to_string(index=False))
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            filename = f"stock_list_{time.strftime('%Y%m%d_%H%M%S')}.csv"
            stocks.to_csv(filename, index=False, encoding='utf-8-sig')
            print(f"\nğŸ’¾ è‚¡ç¥¨åˆ—è¡¨å·²ä¿å­˜åˆ°: {filename}")
        else:
            print("âŒ æœªèƒ½è·å–è‚¡ç¥¨åˆ—è¡¨")
    else:
        print("\nâŒ Tushareè¿æ¥ä¿®å¤å¤±è´¥")
        print("\nğŸ”§ å»ºè®®çš„è§£å†³æ–¹æ¡ˆ:")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œé˜²ç«å¢™è®¾ç½®")
        print("2. å°è¯•ä½¿ç”¨VPNæˆ–ä»£ç†")
        print("3. è”ç³»ç½‘ç»œç®¡ç†å‘˜æ£€æŸ¥ä¼ä¸šç½‘ç»œé™åˆ¶")
        print("4. ç¨åé‡è¯•ï¼Œå¯èƒ½æ˜¯æœåŠ¡å™¨ä¸´æ—¶é—®é¢˜")
        print("5. æ£€æŸ¥Tushare tokenæ˜¯å¦æœ‰æ•ˆ")

if __name__ == "__main__":
    main() 