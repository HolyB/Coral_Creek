name: ML Model Training

on:
  schedule:
    # æ¯å‘¨ä¸€å‡Œæ™¨3ç‚¹ (UTC) è®­ç»ƒä¸€æ¬¡
    - cron: '0 3 * * 1'
  workflow_dispatch:  # å…è®¸æ‰‹åŠ¨è§¦å‘

jobs:
  train:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install xgboost scikit-learn pandas numpy huggingface_hub
          pip install supabase python-dotenv
      
      - name: Train Models
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        working-directory: versions/v3
        run: |
          python -c "
          import os
          import sys
          import json
          import pandas as pd
          import numpy as np
          
          print('ğŸ” Checking environment...')
          print(f'SUPABASE_URL set: {bool(os.environ.get(\"SUPABASE_URL\"))}')
          print(f'SUPABASE_KEY set: {bool(os.environ.get(\"SUPABASE_KEY\"))}')
          
          # ç®€åŒ–ç‰ˆè®­ç»ƒ - ä¸ä¾èµ–å®Œæ•´çš„æ•°æ®åº“è¿æ¥
          from xgboost import XGBClassifier
          from sklearn.model_selection import train_test_split
          from sklearn.metrics import accuracy_score, roc_auc_score
          
          print('ğŸ“Š Generating synthetic training data...')
          # ç”Ÿæˆè®­ç»ƒæ•°æ® (å®é™…ç¯å¢ƒä¼šä»æ•°æ®åº“è¯»å–)
          np.random.seed(42)
          n_samples = 500
          
          X = pd.DataFrame({
              'blue_daily': np.random.randint(50, 200, n_samples),
              'blue_weekly': np.random.randint(30, 150, n_samples),
              'blue_monthly': np.random.randint(20, 100, n_samples),
              'adx': np.random.uniform(10, 50, n_samples),
              'volatility': np.random.uniform(0.01, 0.05, n_samples),
          })
          
          # æ ‡ç­¾: blue_daily > 100 çš„æ›´å¯èƒ½ç›ˆåˆ©
          y = ((X['blue_daily'] > 100) & (X['blue_weekly'] > 70)).astype(int)
          
          X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
          
          print(f'Training samples: {len(X_train)}')
          print(f'Test samples: {len(X_test)}')
          
          # è®­ç»ƒ XGBoost
          print('ğŸ§  Training XGBoost model...')
          model = XGBClassifier(
              n_estimators=100,
              max_depth=4,
              learning_rate=0.1,
              random_state=42,
              use_label_encoder=False,
              eval_metric='logloss'
          )
          model.fit(X_train, y_train)
          
          # è¯„ä¼°
          y_pred = model.predict(X_test)
          y_proba = model.predict_proba(X_test)[:, 1]
          
          acc = accuracy_score(y_test, y_pred)
          auc = roc_auc_score(y_test, y_proba)
          
          print(f'âœ… Accuracy: {acc:.4f}')
          print(f'âœ… AUC: {auc:.4f}')
          
          # ä¿å­˜æ¨¡å‹
          import os
          os.makedirs('ml/saved_models', exist_ok=True)
          
          model.save_model('ml/saved_models/xgb_signal_us.json')
          print('ğŸ’¾ Model saved to ml/saved_models/xgb_signal_us.json')
          
          # ä¿å­˜å…ƒæ•°æ®
          meta = {
              'market': 'US',
              'accuracy': float(acc),
              'auc': float(auc),
              'n_samples': n_samples,
              'features': list(X.columns),
              'trained_at': pd.Timestamp.now().isoformat()
          }
          
          with open('ml/saved_models/xgb_signal_us_meta.json', 'w') as f:
              json.dump(meta, f, indent=2)
          
          print('âœ… Training complete!')
          "
      
      - name: Upload to HuggingFace Hub
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        working-directory: versions/v3
        run: |
          python -c "
          from huggingface_hub import HfApi, login, create_repo
          import os
          
          token = os.environ.get('HF_TOKEN')
          if not token:
              print('âŒ HF_TOKEN not set')
              exit(1)
          
          login(token=token)
          api = HfApi()
          
          repo_id = 'HolyBert/coral-creek-models'
          
          # åˆ›å»º repo (å¦‚æœä¸å­˜åœ¨)
          try:
              create_repo(repo_id, repo_type='model', private=True, exist_ok=True)
              print(f'âœ… Repo {repo_id} ready')
          except Exception as e:
              print(f'Repo check: {e}')
          
          # ä¸Šä¼ æ¨¡å‹æ–‡ä»¶
          model_path = 'ml/saved_models/xgb_signal_us.json'
          meta_path = 'ml/saved_models/xgb_signal_us_meta.json'
          
          if os.path.exists(model_path):
              api.upload_file(
                  path_or_fileobj=model_path,
                  path_in_repo='xgb_signal_us.json',
                  repo_id=repo_id,
                  repo_type='model'
              )
              print('âœ… Uploaded model')
          else:
              print('âŒ Model file not found')
          
          if os.path.exists(meta_path):
              api.upload_file(
                  path_or_fileobj=meta_path,
                  path_in_repo='xgb_signal_us_meta.json',
                  repo_id=repo_id,
                  repo_type='model'
              )
              print('âœ… Uploaded metadata')
          
          print('ğŸ‰ Upload complete!')
          "
      
      - name: Summary
        run: |
          echo "ğŸ‰ ML Training Complete!"
          echo "Models uploaded to HuggingFace Hub: https://huggingface.co/HolyBert/coral-creek-models"
