name: ML Model Training

on:
  schedule:
    # ÊØèÂë®Êó•ÂáåÊô®3ÁÇπ (UTC) = Âåó‰∫¨Êó∂Èó¥Âë®Êó• 11:00 AM
    - cron: '0 3 * * 0'
  workflow_dispatch:  # ÂÖÅËÆ∏ÊâãÂä®Ëß¶Âèë
    inputs:
      days_back:
        description: 'ËÆ≠ÁªÉÊï∞ÊçÆÂ§©Êï∞ (0=ÂÖ®ÈÉ®)'
        required: false
        default: '0'
      tier:
        description: '‰ª∑Ê†ºÂàÜÂ±Ç (all-tiers/standard/penny)'
        required: false
        default: 'all-tiers'

# ÊùÉÈôê - ÂÖÅËÆ∏ÂÜôÂÖ•‰ªìÂ∫ì (Êèê‰∫§Ê®°ÂûãÊñá‰ª∂)
permissions:
  contents: write

jobs:
  train:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: main
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install xgboost lightgbm scikit-learn pandas numpy joblib scipy
          pip install polygon-api-client requests yfinance tqdm
          pip install supabase
          pip install torch --index-url https://download.pytorch.org/whl/cpu
      
      - name: Download database from Supabase
        working-directory: versions/v3
        env:
          PYTHONPATH: ${{ github.workspace }}/versions/v3
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          echo "üì• Syncing scan_results from Supabase..."
          python -c "
          from db.database import init_db
          init_db()
          print('‚úÖ Database initialized')
          "
      
      - name: Fetch stock history
        working-directory: versions/v3
        env:
          PYTHONPATH: ${{ github.workspace }}/versions/v3
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          echo "üìà Fetching stock history for training..."
          python -c "
          from db.database import init_db, get_scanned_dates, query_scan_results
          from ml.pipeline import MLPipeline
          from collections import Counter
          
          init_db()
          dates = get_scanned_dates(market='US')
          
          # Êî∂ÈõÜÊúÄÈ¢ëÁπÅÁöÑ 200 ‰∏™Ê†áÁöÑ
          counts = Counter()
          for d in dates[:60]:
              results = query_scan_results(scan_date=d, market='US', limit=500)
              for r in results:
                  sym = r.get('symbol', '')
                  price = float(r.get('price', 0) or 0)
                  if sym and price > 0:
                      counts[sym] += 1
          
          symbols = [s for s, _ in counts.most_common(300)]
          print(f'Fetching history for {len(symbols)} symbols...')
          
          pipeline = MLPipeline(market='US')
          pipeline.fetch_and_store_history(symbols, days=400, batch_size=10)
          "
      
      - name: Train models
        working-directory: versions/v3
        env:
          PYTHONPATH: ${{ github.workspace }}/versions/v3
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          DAYS="${{ github.event.inputs.days_back || '9999' }}"
          TIER="${{ github.event.inputs.tier || 'all-tiers' }}"
          
          echo "üöÄ Training ML models"
          echo "   Days: $DAYS"
          echo "   Tier: $TIER"
          
          if [ "$TIER" = "all-tiers" ]; then
            python ml/pipeline.py --market US --days "$DAYS" --all-tiers
          else
            python ml/pipeline.py --market US --days "$DAYS" --tier "$TIER"
          fi
          
          echo ""
          echo "üìÇ XGBoost Model files:"
          ls -la ml/saved_models/v2_us/ || echo "No v2_us models"
          ls -la ml/saved_models/v2_us_penny/ 2>/dev/null || echo "No penny models"
      
      - name: Train MMoE models
        working-directory: versions/v3
        env:
          PYTHONPATH: ${{ github.workspace }}/versions/v3
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          TRAIN_TIER: ${{ github.event.inputs.tier || 'all-tiers' }}
          TRAIN_DAYS: ${{ github.event.inputs.days_back || '9999' }}
        run: |
          DAYS="${{ github.event.inputs.days_back || '9999' }}"
          TIER="${{ github.event.inputs.tier || 'all-tiers' }}"
          
          echo "üß† Training MMoE models"
          python << 'PYEOF'
          import warnings; warnings.filterwarnings('ignore')
          from ml.pipeline import MLPipeline
          from ml.models.mmoe import MMoEPredictor, ALL_TASK_DEFS
          import os

          BEST_TASKS = [t for t in ALL_TASK_DEFS if t['name'] != 'volatility']
          kwargs = dict(
              num_experts=4, expert_hidden=64, expert_out=32, tower_hidden=16,
              dropout=0.2, lr=5e-4, weight_decay=1e-3,
              epochs=200, batch_size=128, patience=25,
              task_defs=BEST_TASKS,
          )

          tier = os.environ.get('TRAIN_TIER', 'all-tiers')
          days = int(os.environ.get('TRAIN_DAYS', '9999'))
          tiers = ['standard', 'penny'] if tier == 'all-tiers' else [tier]

          for t in tiers:
              print(f'\n=== MMoE {t} ===')
              p = MLPipeline(market='US', days_back=days, price_tier=t)
              X, ret, dd, grp, fn, info = p.prepare_dataset()
              mmoe = MMoEPredictor(**kwargs)
              r = mmoe.train(X, ret, fn, grp, dd)
              suffix = '_penny' if t == 'penny' else ''
              mmoe.save(f'ml/saved_models/v2_us{suffix}_mmoe')
              print(f'  dir={r["dir_accuracy"]:.1%}, mae5={r["mae_5d"]:.2f}%')
          PYEOF
          
          echo ""
          echo "üìÇ MMoE Model files:"
          ls -la ml/saved_models/v2_us_mmoe/ || echo "No MMoE standard"
          ls -la ml/saved_models/v2_us_penny_mmoe/ 2>/dev/null || echo "No MMoE penny"
      
      - name: Verify models
        working-directory: versions/v3
        run: |
          python -c "
          import joblib, json, os
          
          for tier_dir in ['ml/saved_models/v2_us', 'ml/saved_models/v2_us_penny',
                          'ml/saved_models/v2_us_mmoe', 'ml/saved_models/v2_us_penny_mmoe']:
              if not os.path.exists(tier_dir):
                  continue
              tier = tier_dir.split('/')[-1]
              print(f'\nüìä {tier}:')
              
              for f in sorted(os.listdir(tier_dir)):
                  path = os.path.join(tier_dir, f)
                  if os.path.isfile(path):
                      size = os.path.getsize(path)
                      print(f'  ‚úÖ {f} ({size:,} bytes)')
              
              # XGBoost check
              fn_path = os.path.join(tier_dir, 'feature_names.json')
              if os.path.exists(fn_path):
                  with open(fn_path) as fh:
                      features = json.load(fh)
                  print(f'  Features: {len(features)}')
              
              model_path = os.path.join(tier_dir, 'return_5d.joblib')
              if os.path.exists(model_path):
                  model = joblib.load(model_path)
                  print(f'  XGBoost loaded: {type(model).__name__}')
              
              # MMoE check
              mmoe_path = os.path.join(tier_dir, 'mmoe_meta.json')
              if os.path.exists(mmoe_path):
                  with open(mmoe_path) as fh:
                      meta = json.load(fh)
                  print(f'  MMoE: {len(meta.get("feature_names",[]))} features, tasks={[t["name"] for t in meta.get("task_defs",[])]}')
          "
      
      - name: Commit updated models
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          git add versions/v3/ml/saved_models/ || true
          
          if git diff --staged --quiet; then
            echo "No model changes to commit"
          else
            COMMIT_MSG="üß† Auto-retrain: ML models $(date +%Y-%m-%d)"
            git commit -m "$COMMIT_MSG"
            
            if ! git pull --rebase origin main; then
              git rebase --abort || true
              git pull -X ours origin main || true
            fi
            git push origin HEAD:main
          fi
      
      - name: Upload models to HuggingFace Hub
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        working-directory: versions/v3
        run: |
          pip install huggingface_hub
          python -c "
          from huggingface_hub import HfApi, login, create_repo
          import os
          
          token = os.environ.get('HF_TOKEN')
          if not token:
              print('‚ö†Ô∏è HF_TOKEN not set, skipping upload')
              exit(0)
          
          login(token=token)
          api = HfApi()
          repo_id = 'HolyBert/coral-creek-models'
          
          try:
              create_repo(repo_id, repo_type='model', private=True, exist_ok=True)
          except Exception as e:
              print(f'Repo check: {e}')
          
          for tier_dir in ['ml/saved_models/v2_us', 'ml/saved_models/v2_us_penny',
                          'ml/saved_models/v2_us_mmoe', 'ml/saved_models/v2_us_penny_mmoe']:
              if not os.path.exists(tier_dir):
                  continue
              tier = tier_dir.split('/')[-1]
              for f in os.listdir(tier_dir):
                  fpath = os.path.join(tier_dir, f)
                  if os.path.isfile(fpath):
                      api.upload_file(
                          path_or_fileobj=fpath,
                          path_in_repo=f'{tier}/{f}',
                          repo_id=repo_id,
                          repo_type='model'
                      )
                      print(f'  ‚úÖ Uploaded: {tier}/{f}')
          
          print('üéâ Upload complete!')
          "
      
      - name: Summary
        run: |
          echo "üéâ ML Training Complete!"
          echo "Models: XGBoost (Standard+Penny) + MMoE 5-task (Standard+Penny)"
          echo "MMoE tasks: return_5d, return_20d, direction, max_dd, rank_score"
          echo "Features: 110 technical + fundamental indicators"
          echo "Used by: SmartPicker (MMoE primary, XGBoost fallback)"
