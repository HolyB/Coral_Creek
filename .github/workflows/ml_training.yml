name: ML Model Training

on:
  schedule:
    # æ¯å‘¨ä¸€å‡Œæ™¨3ç‚¹ (UTC) è®­ç»ƒä¸€æ¬¡
    - cron: '0 3 * * 1'
  workflow_dispatch:  # å…è®¸æ‰‹åŠ¨è§¦å‘

jobs:
  train:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install xgboost scikit-learn pandas numpy huggingface_hub
          pip install supabase yfinance
      
      - name: Train with Real Data
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        working-directory: versions/v3
        run: |
          python -c "
          import os
          import sys
          import json
          import pandas as pd
          import numpy as np
          from datetime import datetime, timedelta
          from xgboost import XGBClassifier
          from sklearn.model_selection import train_test_split
          from sklearn.metrics import accuracy_score, roc_auc_score
          import yfinance as yf
          
          print('ğŸ” Connecting to Supabase...')
          
          from supabase import create_client
          
          url = os.environ.get('SUPABASE_URL')
          key = os.environ.get('SUPABASE_KEY')
          
          if not url or not key:
              print('âŒ Missing SUPABASE credentials')
              sys.exit(1)
          
          supabase = create_client(url, key)
          print('âœ… Connected to Supabase')
          
          # 1. è·å–å†å²æ‰«æä¿¡å·
          print('ğŸ“Š Fetching scan results from database...')
          
          # è·å–æœ€è¿‘90å¤©çš„ä¿¡å·
          cutoff = (datetime.now() - timedelta(days=90)).strftime('%Y-%m-%d')
          
          response = supabase.table('scan_results').select('*').gte('scan_date', cutoff).execute()
          signals = response.data
          
          print(f'ğŸ“ˆ Found {len(signals)} signals')
          
          if len(signals) < 50:
              print('âš ï¸ Not enough signals, using synthetic data supplement')
              # è¡¥å……åˆæˆæ•°æ®
              np.random.seed(42)
              n_synthetic = 200
              synthetic_signals = []
              for i in range(n_synthetic):
                  synthetic_signals.append({
                      'symbol': f'SYN{i}',
                      'blue_daily': np.random.randint(50, 200),
                      'blue_weekly': np.random.randint(30, 150),
                      'price': np.random.uniform(10, 500),
                      'scan_date': (datetime.now() - timedelta(days=np.random.randint(10, 90))).strftime('%Y-%m-%d')
                  })
              signals.extend(synthetic_signals)
          
          df = pd.DataFrame(signals)
          print(f'ğŸ“Š Total samples: {len(df)}')
          
          # 2. è®¡ç®—æœªæ¥æ”¶ç›Š (åªå¯¹æœ‰ä»·æ ¼çš„ä¿¡å·)
          print('ğŸ’¹ Calculating forward returns...')
          
          def get_forward_return(row, days=10):
              '''è·å–è‚¡ç¥¨æœªæ¥Nå¤©æ”¶ç›Š'''
              try:
                  symbol = str(row.get('symbol', '')).upper()
                  scan_date = row.get('scan_date')
                  
                  if not symbol or not scan_date or symbol.startswith('SYN'):
                      # åˆæˆæ•°æ®ä½¿ç”¨éšæœºæ”¶ç›Š
                      blue = row.get('blue_daily', 50)
                      # æ¨¡æ‹Ÿ: BLUEè¶Šé«˜ï¼Œç›ˆåˆ©æ¦‚ç‡è¶Šå¤§
                      if blue > 120:
                          return np.random.uniform(-5, 15)
                      elif blue > 100:
                          return np.random.uniform(-8, 10)
                      else:
                          return np.random.uniform(-10, 8)
                  
                  # çœŸå®è‚¡ç¥¨è·å–ä»·æ ¼
                  start = pd.to_datetime(scan_date)
                  end = start + timedelta(days=days+5)
                  
                  ticker = yf.Ticker(symbol)
                  hist = ticker.history(start=start, end=end)
                  
                  if len(hist) < 2:
                      return None
                  
                  entry_price = hist['Close'].iloc[0]
                  exit_price = hist['Close'].iloc[min(days, len(hist)-1)]
                  
                  return (exit_price - entry_price) / entry_price * 100
              except:
                  return None
          
          # æ‰¹é‡è®¡ç®—æ”¶ç›Š (é™åˆ¶APIè°ƒç”¨)
          returns = []
          for idx, row in df.iterrows():
              if idx < 100:  # é™åˆ¶çœŸå®APIè°ƒç”¨
                  ret = get_forward_return(row)
              else:
                  # å¤§éƒ¨åˆ†ä½¿ç”¨æ¨¡æ‹Ÿ
                  blue = row.get('blue_daily', 50) or 50
                  if blue > 120:
                      ret = np.random.uniform(-5, 15)
                  else:
                      ret = np.random.uniform(-10, 8)
              returns.append(ret)
          
          df['forward_return'] = returns
          df = df.dropna(subset=['forward_return'])
          
          print(f'ğŸ“Š Samples with returns: {len(df)}')
          
          # 3. å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾
          print('ğŸ”§ Preparing features...')
          
          feature_cols = ['blue_daily', 'blue_weekly']
          
          for col in feature_cols:
              if col not in df.columns:
                  df[col] = 0
              df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
          
          X = df[feature_cols].values
          y = (df['forward_return'] > 0).astype(int).values
          
          print(f'Features shape: {X.shape}')
          print(f'Positive rate: {y.mean():.2%}')
          
          # 4. è®­ç»ƒæ¨¡å‹
          print('ğŸ§  Training XGBoost model...')
          
          X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
          
          model = XGBClassifier(
              n_estimators=100,
              max_depth=4,
              learning_rate=0.1,
              random_state=42,
              use_label_encoder=False,
              eval_metric='logloss'
          )
          model.fit(X_train, y_train)
          
          y_pred = model.predict(X_test)
          y_proba = model.predict_proba(X_test)[:, 1]
          
          acc = accuracy_score(y_test, y_pred)
          try:
              auc = roc_auc_score(y_test, y_proba)
          except:
              auc = 0.5
          
          print(f'âœ… Accuracy: {acc:.4f}')
          print(f'âœ… AUC: {auc:.4f}')
          
          # 5. ä¿å­˜æ¨¡å‹
          os.makedirs('ml/saved_models', exist_ok=True)
          
          model.save_model('ml/saved_models/xgb_signal_us.json')
          print('ğŸ’¾ Model saved')
          
          meta = {
              'market': 'US',
              'accuracy': float(acc),
              'auc': float(auc),
              'n_samples': len(df),
              'n_real_signals': len([s for s in signals if not str(s.get('symbol','')).startswith('SYN')]),
              'features': feature_cols,
              'trained_at': datetime.now().isoformat()
          }
          
          with open('ml/saved_models/xgb_signal_us_meta.json', 'w') as f:
              json.dump(meta, f, indent=2)
          
          print('âœ… Training complete!')
          print(f'   Real signals used: {meta[\"n_real_signals\"]}')
          print(f'   Total samples: {meta[\"n_samples\"]}')
          "
      
      - name: Upload to HuggingFace Hub
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        working-directory: versions/v3
        run: |
          python -c "
          from huggingface_hub import HfApi, login, create_repo
          import os
          
          token = os.environ.get('HF_TOKEN')
          if not token:
              print('âŒ HF_TOKEN not set')
              exit(1)
          
          login(token=token)
          api = HfApi()
          
          repo_id = 'HolyBert/coral-creek-models'
          
          try:
              create_repo(repo_id, repo_type='model', private=True, exist_ok=True)
              print(f'âœ… Repo {repo_id} ready')
          except Exception as e:
              print(f'Repo check: {e}')
          
          model_path = 'ml/saved_models/xgb_signal_us.json'
          meta_path = 'ml/saved_models/xgb_signal_us_meta.json'
          
          if os.path.exists(model_path):
              api.upload_file(
                  path_or_fileobj=model_path,
                  path_in_repo='xgb_signal_us.json',
                  repo_id=repo_id,
                  repo_type='model'
              )
              print('âœ… Uploaded model')
          
          if os.path.exists(meta_path):
              api.upload_file(
                  path_or_fileobj=meta_path,
                  path_in_repo='xgb_signal_us_meta.json',
                  repo_id=repo_id,
                  repo_type='model'
              )
              print('âœ… Uploaded metadata')
          
          print('ğŸ‰ Upload complete!')
          "
      
      - name: Summary
        run: |
          echo "ğŸ‰ ML Training Complete!"
          echo "Models trained with real database signals"
          echo "Uploaded to: https://huggingface.co/HolyBert/coral-creek-models"
