name: Daily Stock Scan

on:
  # å®šæ—¶è§¦å‘ - ç¾ä¸œæ—¶é—´
  schedule:
    # ç›˜å‰: UTC 13:00 = ç¾ä¸œ 8:00 AM
    - cron: '0 13 * * 1-5'
    # ç›˜å: UTC 21:30 = ç¾ä¸œ 16:30 (30åˆ†é’Ÿå)
    - cron: '30 21 * * 1-5'
  
  # æ‰‹åŠ¨è§¦å‘
  workflow_dispatch:
    inputs:
      scan_date:
        description: 'Scan date (YYYY-MM-DD), leave empty for today'
        required: false
        default: ''
      limit:
        description: 'Limit number of stocks (0 = all)'
        required: false
        default: '0'

# æƒé™ - å…è®¸å†™å…¥ä»“åº“
permissions:
  contents: write

env:
  POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}


jobs:
  scan:
    runs-on: ubuntu-latest
    timeout-minutes: 60  # æœ€é•¿è¿è¡Œ1å°æ—¶
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy plotly polygon-api-client tqdm requests python-dotenv
      
      - name: Run daily scan
        working-directory: versions/v2
        env:
          TZ: America/New_York
          PYTHONPATH: ${{ github.workspace }}/versions/v2
        run: |
          # ç¡®å®šæ‰«ææ—¥æœŸ (ä½¿ç”¨ç¾ä¸œæ—¶é—´)
          SCAN_DATE="${{ github.event.inputs.scan_date }}"
          if [ -z "$SCAN_DATE" ]; then
            # ä½¿ç”¨ç¾ä¸œæ—¶é—´è·å–æ—¥æœŸ
            SCAN_DATE=$(TZ='America/New_York' date +%Y-%m-%d)
          fi
          
          LIMIT="${{ github.event.inputs.limit }}"
          if [ -z "$LIMIT" ]; then
            LIMIT="0"
          fi
          
          echo "ğŸ“… Scanning for date: $SCAN_DATE (Eastern Time)"
          echo "ğŸ“Š Stock limit: $LIMIT"
          echo "ğŸ”§ PYTHONPATH: $PYTHONPATH"
          
          # åˆ›å»ºæ•°æ®åº“ç›®å½•
          mkdir -p db
          
          # è¿è¡Œæ‰«æ
          python services/scan_service.py --date "$SCAN_DATE" --workers 10 --limit "$LIMIT"
      
      - name: Generate scan report
        working-directory: versions/v2
        run: |
          python -c "
          from db.database import get_db_stats, query_scan_results, get_scanned_dates, get_stock_info_batch
          from data_fetcher import get_us_stock_data
          from chart_utils import quick_chip_analysis
          import json
          
          stats = get_db_stats()
          print('ğŸ“Š Scan Statistics:')
          print(f'   Total records: {stats[\"total_records\"]}')
          print(f'   Total symbols: {stats[\"total_symbols\"]}')
          print(f'   Date range: {stats[\"min_date\"]} ~ {stats[\"max_date\"]}')
          
          # è·å–æœ€æ–°æ‰«æç»“æœ
          dates = get_scanned_dates(market='US')
          if dates:
              latest = dates[0]
              results = query_scan_results(scan_date=latest, market='US', limit=20)
              
              # è·å–è‚¡ç¥¨åç§°
              symbols = [r['symbol'] for r in results]
              stock_info = get_stock_info_batch(symbols) if symbols else {}
              
              print(f'\nğŸ† Top 20 signals for {latest}:')
              for r in results:
                  info = stock_info.get(r['symbol'], {})
                  name = info.get('name', '')[:15] if info else ''
                  print(f'   {r[\"symbol\"]:6} | {name:15} | \${r[\"price\"]:8.2f} | BLUE: {r[\"blue_daily\"]:5.1f}')
              
              # æ„å»º top_signals (åŒ…å«ç­¹ç åˆ†æ)
              print('\nğŸ” Analyzing chip distribution...')
              top_signals = []
              for r in results[:15]:
                  info = stock_info.get(r['symbol'], {})
                  chip_pattern = ''
                  try:
                      stock_df = get_us_stock_data(r['symbol'], days=100)
                      if stock_df is not None and len(stock_df) >= 30:
                          chip_result = quick_chip_analysis(stock_df)
                          if chip_result:
                              chip_pattern = chip_result.get('label', '')
                  except Exception as e:
                      print(f'   Chip analysis error for {r[\"symbol\"]}: {e}')
                  
                  top_signals.append({
                      'symbol': r['symbol'],
                      'name': info.get('name', '') if info else '',
                      'price': r['price'],
                      'day_blue': r['blue_daily'],
                      'week_blue': r['blue_weekly'],
                      'chip_pattern': chip_pattern
                  })
                  if chip_pattern:
                      print(f'   {r[\"symbol\"]:6} -> {chip_pattern}')
              
              # ä¿å­˜æ‘˜è¦åˆ°æ–‡ä»¶
              summary = {
                  'date': latest,
                  'market': 'US',
                  'total_signals': len(query_scan_results(scan_date=latest, market='US')),
                  'top_signals': top_signals
              }
              with open('scan_summary.json', 'w') as f:
                  json.dump(summary, f, indent=2, ensure_ascii=False)
          "
      
      - name: Upload database artifact
        uses: actions/upload-artifact@v4
        with:
          name: scan-database-${{ github.run_number }}
          path: versions/v2/db/coral_creek.db
          retention-days: 30
      
      - name: Upload scan summary
        uses: actions/upload-artifact@v4
        with:
          name: scan-summary-${{ github.run_number }}
          path: versions/v2/scan_summary.json
          retention-days: 30
          if-no-files-found: ignore
      
      # å‘é€é€šçŸ¥ (Telegram + Email)
      - name: Send notifications
        working-directory: versions/v2
        env:
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
          WECOM_WEBHOOK: ${{ secrets.WECOM_WEBHOOK }}
          WXPUSHER_APP_TOKEN: ${{ secrets.WXPUSHER_APP_TOKEN }}
          WXPUSHER_UIDS: ${{ secrets.WXPUSHER_UIDS }}
          WXPUSHER_TOPIC_IDS: ${{ secrets.WXPUSHER_TOPIC_IDS }}
          BARK_URL: ${{ secrets.BARK_URL }}
          BARK_GROUP: ${{ secrets.BARK_GROUP }}
          SMTP_HOST: ${{ secrets.SMTP_HOST }}
          SMTP_PORT: ${{ secrets.SMTP_PORT }}
          SMTP_SENDER: ${{ secrets.SMTP_SENDER }}
          SMTP_PASSWORD: ${{ secrets.SMTP_PASSWORD }}
          EMAIL_RECEIVERS: ${{ secrets.EMAIL_RECEIVERS }}
        run: |
          python scripts/send_notification.py
      
      # åŒæ­¥åˆ° Supabase äº‘æ•°æ®åº“
      - name: Sync to Supabase
        working-directory: versions/v2
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          pip install supabase
          python scripts/sync_to_supabase.py --days 14
      
      # å‘é€ä»Šæ—¥ç²¾é€‰åˆ° Telegram (ä½¿ç”¨ V3 ç­–ç•¥ç³»ç»Ÿ)
      - name: Send daily picks
        working-directory: versions/v3
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
          WECOM_WEBHOOK: ${{ secrets.WECOM_WEBHOOK }}
          WXPUSHER_APP_TOKEN: ${{ secrets.WXPUSHER_APP_TOKEN }}
          WXPUSHER_UIDS: ${{ secrets.WXPUSHER_UIDS }}
          WXPUSHER_TOPIC_IDS: ${{ secrets.WXPUSHER_TOPIC_IDS }}
          BARK_URL: ${{ secrets.BARK_URL }}
          BARK_GROUP: ${{ secrets.BARK_GROUP }}
        run: |
          pip install supabase pandas numpy
          python scripts/send_daily_picks.py --market US
      
      # å‘é€ä¹°å–ä¿¡å·åˆ° Telegram
      - name: Send trading signals
        working-directory: versions/v3
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
          WECOM_WEBHOOK: ${{ secrets.WECOM_WEBHOOK }}
          WXPUSHER_APP_TOKEN: ${{ secrets.WXPUSHER_APP_TOKEN }}
          WXPUSHER_UIDS: ${{ secrets.WXPUSHER_UIDS }}
          WXPUSHER_TOPIC_IDS: ${{ secrets.WXPUSHER_TOPIC_IDS }}
          BARK_URL: ${{ secrets.BARK_URL }}
          BARK_GROUP: ${{ secrets.BARK_GROUP }}
        run: |
          python scripts/send_trading_signals.py --market US

      # å›å¡«å¹¶åˆ·æ–° candidate_trackingï¼ˆé¿å…ç­–ç•¥ç»Ÿè®¡æ ·æœ¬ä¸º0æˆ–æ”¶ç›Šå…¨0ï¼‰
      - name: Rebuild candidate tracking (US)
        working-directory: versions/v3
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          mkdir -p db
          cp ../v2/db/coral_creek.db db/coral_creek.db || true
          python scripts/backfill_candidate_tracking.py --market US --recent-days 420 --max-per-day 800 --refresh-rows 12000
          cp db/coral_creek.db ../v2/db/coral_creek.db || true
      
      # é¢„è®¡ç®—é€€å‡ºè§„åˆ™ç»“æœï¼ˆå…¨é‡æ•°æ®ï¼Œå‰ç«¯ç§’å‡ºï¼‰
      - name: Pre-compute exit rule results (US)
        working-directory: versions/v3
        timeout-minutes: 45
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          python scripts/precompute_exit_results.py --market US --rules fixed_5d,fixed_10d,fixed_20d,tp_sl_time --batch-size 5000
      
      # é¢„è®¡ç®— MMoE æ’ååˆ†ï¼ˆé¡µé¢ç§’å¼€ï¼‰
      - name: Pre-compute MMoE scores (US)
        working-directory: versions/v3
        env:
          PYTHONPATH: ${{ github.workspace }}/versions/v3
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        continue-on-error: true  # MMoE æ˜¯å¢å¼ºåŠŸèƒ½ï¼Œä¸é˜»æ–­ä¸»æµç¨‹
        run: |
          pip install torch --index-url https://download.pytorch.org/whl/cpu 2>/dev/null || true
          pip install xgboost lightgbm scikit-learn joblib scipy 2>/dev/null || true
          python scripts/precompute_mmoe_scores.py --market US
      
      # æäº¤æ•°æ®åº“åˆ°ä»“åº“ - ç”¨äº Streamlit Cloud
      - name: Commit database to repo
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          # åŒæ­¥ v2 æ•°æ®åº“åˆ° v3ï¼ˆv3 Streamlit é¡µé¢è¯»å–ï¼‰
          mkdir -p versions/v3/db
          cp versions/v2/db/coral_creek.db versions/v3/db/coral_creek.db || true
          
          # æ·»åŠ æ•°æ®åº“æ–‡ä»¶
          git add versions/v2/db/coral_creek.db || true
          git add versions/v3/db/coral_creek.db || true
          git add versions/v3/db/precomputed.db || true
          git add versions/v2/scan_summary.json || true
          git add versions/v3/ml/saved_models/mmoe_cache/ || true
          
          # æ£€æŸ¥æ˜¯å¦æœ‰å˜åŒ–
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "ğŸ“Š Auto-update: Scan results for $(TZ='America/New_York' date +%Y-%m-%d)"
            
            # å°è¯• rebaseï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨ ours ç­–ç•¥åˆå¹¶
            if ! git pull --rebase origin main; then
              echo "Rebase failed, resolving conflicts with ours strategy..."
              git rebase --abort || true
              git pull -X ours origin main || true
              git push || git push --force-with-lease
            else
              git push
            fi
          fi
